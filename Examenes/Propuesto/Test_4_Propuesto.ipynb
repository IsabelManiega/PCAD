{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f145a4f8-df21-4d80-aa30-42967c8f3c19",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83643f4e-14fd-41c0-85ad-18560eb81f40",
   "metadata": {},
   "source": [
    "# Test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1de6f7-ddc5-4122-91a1-60656a166e63",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8015c-5a0a-43b1-95eb-94a3360d5dd2",
   "metadata": {},
   "source": [
    "```\n",
    "Emma is cleaning a sales dataset and notices that the ‘sale_amount’ column has several entries labeled as ‘confidential’. How should Emma treat these entries during the data cleaning process?\n",
    "\n",
    "a) As valid data, because 'confidential' indicates a special data category.\n",
    "b) As missing data, since 'confidential' does not provide a numerical value.\n",
    "c) As duplicate data, assuming 'confidential' is a repeated placehoder.\n",
    "d) As categorical data, because 'confidential' implies a different data grouping.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50d971-2a4c-47b7-a5dd-96f4013de662",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79186275-3945-4d6a-b514-dd92485c4e60",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376ed41-76db-4b5b-8399-b4f409d2d5d2",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bb637-da9f-4ac3-9c63-9982c756a57f",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48aac7d-2db5-471e-80de-dc4b336d455a",
   "metadata": {},
   "source": [
    "You have a list of strings and need to concatenate them into a single string with spaces between each element. Which code snippet achieves this task? \n",
    "\n",
    "```strings_list = [“hello”, “world”, “python”]```\n",
    "\n",
    "a) ```\"\".join(strings_list)```\n",
    "\n",
    "b) ```\"\".concatenate(strings_list)```\n",
    "\n",
    "c) ```strings_list.join(\"\")```\n",
    "\n",
    "d) ```strings_list.concatenate(\"\")```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b58b0-04bc-4602-a9f4-bd20ddb76a01",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55962c01-9ee5-4a1a-8367-844976dd7a01",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854a23e-3258-454a-9986-74a9b126602e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba237a-0ecd-4e1b-87d4-e3ac946aff9b",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c33c3-e889-43c1-bf42-df3a652b8c13",
   "metadata": {},
   "source": [
    "You are creating a presentation and need to include a plot that shows the correlation between two numerical variables. You want to make sure the plot looks professional and can be easily understood when projected on a screen. What should you consider for this plot?\n",
    "\n",
    "a) Use a 3D scatter plot with rainbow color map.\n",
    "\n",
    "b) Use a 2D scatter plot with a single, high-contrast color and large markers.\n",
    "\n",
    "c) Use a pie chart to represent each variable, side by side.\n",
    "\n",
    "d) Use a line plot with highly stylized, decorative fonts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbbeb7-9e95-485d-b354-3543d50e87bf",
   "metadata": {},
   "source": [
    "## Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbc376-9550-413b-8bdd-e61bec982946",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277820e-9973-401e-8c61-52ec4b6d3fc8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefe86a-6267-4a06-b789-cf0c9d6135ee",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa161b64-4575-42fa-ad29-e45cb7f6d22d",
   "metadata": {},
   "source": [
    "```\n",
    "You need to create a dashboard to monitor key performance indicators (KPIs) for a marketing campaign. Which dashboard-building tool would be most appropriate for integrating real-time data sources and automating data refreshes for up-to-date insights?\n",
    "\n",
    "a) Microsoft Power BI\n",
    "b) Google Data Studio.\n",
    "c) Tableau.\n",
    "d) Qlik Sense\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edfcb98-b6e3-4d03-ba74-543098fa38d2",
   "metadata": {},
   "source": [
    "## Solution 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada42a5-28d0-4d7b-a5e8-fc6c089fa064",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f45465-de21-431f-8a8d-1dbae81ea8b0",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b6379-0d11-4b3d-8eeb-c13eb31c29f7",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef3e85-451f-4c06-be06-1e20e7a26f5a",
   "metadata": {},
   "source": [
    "```\n",
    "During the data preparation stage, Mike finds that several entries in the ’email’ column of a customer database contain strings that do not include an ‘@’ symbol. How should Mike handle these entries in the context of data cleaning?\n",
    "\n",
    "a) As complete data, because the email column is populated.\n",
    "b) As valid data, assuming the '@' symbol was mistakenly omitted.\n",
    "c) As missing data, since they do not represent valid email addresses.\n",
    "d) As incorrect data, because the fail to meet the standard email format.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758539bb-cc2c-46af-b94e-0ce75027eda7",
   "metadata": {},
   "source": [
    "## Solution 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548c9b2-077e-45ab-8a97-7521a6f48091",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501b09a-ff4f-4d43-a367-3b76c21c91f4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21975f72-3fbc-4e82-9306-03f17d81e502",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641f690-f49a-4ebf-b090-bbc0e9e3c6a0",
   "metadata": {},
   "source": [
    "You are analyzing a dataset containing customer ages, and you notice that some entries in the “Age” column are negative values. What would you consider as a common data quality issue in this scenario?\n",
    "\n",
    "a) Entries with missing values in the \"Age\" column.\n",
    "\n",
    "b) Entries with positive values in the \"Age\" column.\n",
    "\n",
    "c) Entries with inconsistent formatting in the \"Age\" column.\n",
    "\n",
    "d) Entries with incorrect values in the \"Age\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bb4c6-9164-4dd9-ac21-83492c671da1",
   "metadata": {},
   "source": [
    "## Solution 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd05ca9-c2f6-415e-bc4e-d549732a69c4",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72045474-4104-4e38-8a5a-e74fa4768be9",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddd3c4-9267-4bc7-bf4c-ffd901f2c14f",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a12903-3dcb-4e66-9cd2-af6376a281a6",
   "metadata": {},
   "source": [
    "```\n",
    "Rachel is analyzing a sales dataset and notices that some entries under the ‘sales_amount’ column are labeled as ‘confidential’ instead of showing actual numbers. How should Rachel address this issue to ensure data quality?\n",
    "\n",
    "a) Treat 'confidential' as a high-value sale to highlight potential maximum sales.\n",
    "b) Replace 'confidential' with the average of the 'sales_amount' column.\n",
    "c) Remove all records with 'confidential' sales amounts.\n",
    "d) Consult with the data provider to understand the meaning of 'confidential' and decide on the most appropiate action.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e1b6f-d662-4980-9869-129e72505e8b",
   "metadata": {},
   "source": [
    "## Solution 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7738b-1b51-4d7a-8f3d-b02a9c6506b3",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11441ad2-5297-4168-b80b-aab343d4279d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be55bfb-c9f2-4143-a82b-67712953f5d8",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a795f-7960-4c2c-a869-be1977a53e84",
   "metadata": {},
   "source": [
    "```\n",
    "A research team is studying the dietary habits of teenagers in a particular region to identify trends and health implications. They need to collect detailed, personalized data over a period of six months. Which data collection method would be most appropriate for this study?\n",
    "\n",
    "a) Direct observation in schools.\n",
    "b) Online food diaries.\n",
    "c) National heath surveys.\n",
    "d) Public health records.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0254a-bec4-40f1-ac5b-6d913f1c5359",
   "metadata": {},
   "source": [
    "## Solution 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc680854-2a30-4ed4-affc-e09d6c7fdde0",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3a5aa-20d4-4a30-a352-a3aa7e4ecf1d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d596dff-ec22-4cab-9ff5-ed5bf307a51a",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b1752-e7e0-42a2-baac-934f2540f4c9",
   "metadata": {},
   "source": [
    "```\n",
    "Samantha is cleaning a healthcare dataset and finds that the ‘blood_pressure’ column has some unusually high values, such as 999 or 1000, which are clinically unrealistic. What should Samantha do to address these anomalies?\n",
    "\n",
    "a) Leave the values as is, considering them as outliers that can be ignored.\n",
    "b) replace these unrealistic values with the column average.\n",
    "c) Mark these values as missing and handle them as part of the dataset's missing data.\n",
    "d) Verify the values with healthcare professionals and correct them based on clinical advice.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680e6be-7989-4c54-a0f4-66c80a29c8af",
   "metadata": {},
   "source": [
    "## Solution 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469d2e4-e3df-485f-9f7d-473407d530b3",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128a9e1-5276-4c15-ac80-04155ad00d0a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659197bd-337e-4349-8ac0-22135e1537ac",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c2460-e7ce-4b9f-9d80-822ff74df3ea",
   "metadata": {},
   "source": [
    "Which one of the following methods returns the root element in the *xml.etree.ElementTree* module?\n",
    "\n",
    "a) root\n",
    "\n",
    "b) getroot\n",
    "\n",
    "c) getparent\n",
    "\n",
    "d) parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989db20b-e328-4f1f-8216-ca5113cda68c",
   "metadata": {},
   "source": [
    "## Solution 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e1245-2b2a-4ad5-8ebc-5582c03a7f14",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca2c77-b508-4b04-a937-ec18dc6cc8d3",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcfc895-53b0-4987-b413-8e5091108c64",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca7c95-712c-4968-b868-0098c52b454f",
   "metadata": {},
   "source": [
    "```\n",
    "You are tasked with preparing a dataset for a machine learning model. The dataset contains missing values in several columns. What preprocessing technique should you apply to handle missing values before modeling?\n",
    "\n",
    "a) Remove rows with missing values.\n",
    "b) Replace missing values with the mean of the column.\n",
    "c) Use the most frequent value to replace missing values.\n",
    "d) Apply linear regression to predict missing values.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a713a-d66a-4896-bde5-806e923b93f0",
   "metadata": {},
   "source": [
    "## Solution 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50482d2f-2da1-4a2e-a40d-2bf575fb6317",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0c4e6-31eb-45aa-adf7-12b1720a8042",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb31a73-2d39-4dc2-b27f-4edf6a8791f8",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b12b27-b82d-4f02-9b8c-f791361b7e1d",
   "metadata": {},
   "source": [
    "```\n",
    "You are developing a dashboard for a retail company to track inventory and supply chain performance. Which combination of metrics would be most relevant for this dashboard to optimize inventory management and logistics?\n",
    "\n",
    "a) Inventory turnover ratio, stockout rate, lead time.\n",
    "b) Customer retention rate, sales revenue, market share.\n",
    "c) Employee productivity, training hours, satisfaction survey results.\n",
    "d) Website traffic, social media followers, online sales conversion rate.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d455c-f48a-451c-badb-632e9def8ccd",
   "metadata": {},
   "source": [
    "## Solution 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019caf38-51e7-4b4d-a464-2a1bd1a31335",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602faac-d520-45e7-8fb3-67b80bf26bc1",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec6d5d-5d3e-4a6c-ae1f-f8f7afed6110",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49906b-c026-48cc-b6cb-6e280c2f986c",
   "metadata": {},
   "source": [
    "```\n",
    "You are designing a dashboard for a transportation company to monitor fleet performance and logistics efficiency. Which combination of metrics would be most relevant for this dashboard to improve fleet operations and delivery timelines?\n",
    "\n",
    "a) Vehicle utilization rate, on.time delivery rate, fuel efficiency.\n",
    "b) Customer acquisition cost, revenue growth, market share.\n",
    "c) Employee turnover rate, training completion rate, job satifaction score.\n",
    "d) Website traffic, social media engagement, onlie sales revenue.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f60fc-aeec-413c-8b51-7d30d5d6de5c",
   "metadata": {},
   "source": [
    "## Solution 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e629a-3d59-4247-a1bd-18b7e481f9cd",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c3ddf-7df3-43f2-8222-7548a6a731ff",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd113c-315d-41d7-8d97-b453da9e0bd7",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e68c9-1219-4a05-b691-e529b7437525",
   "metadata": {},
   "source": [
    "```\n",
    "A data analyst needs to source financial data for multiple companies over the last decade to perform a market trend analysis. Which approach would be most efficient and reliable for collecting this type of data?\n",
    "\n",
    "a) Conducting interviews with indsutry experts.\n",
    "b) Accessing a financial market database through an API.\n",
    "c) Collecting data from printed financial magazines.\n",
    "d) Using social media analytics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780908a-befa-4f8f-b606-469f88c3427e",
   "metadata": {},
   "source": [
    "## Solution 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31834bcd-c769-480a-84c2-d4af1e7d389a",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a08f9-172f-45dd-b949-7102850dbfa4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4718c-374b-477f-bdb5-b9288d6350b7",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee08698-2e1f-45e1-b0d7-0667ce86731c",
   "metadata": {},
   "source": [
    "In the csv module, saving data to a csv file is possible using:\n",
    "\n",
    "(Select all that apply.)\n",
    "\n",
    "a) The ```DictWriter``` class\n",
    "\n",
    "b) The ```write_csv``` function\n",
    "\n",
    "c) the ```writer``` function\n",
    "\n",
    "d) the ```Csv_writer``` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d854a33-35db-4cc5-bafb-6f1189d9a706",
   "metadata": {},
   "source": [
    "## Solution 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b07b83-8c95-4bdf-83d7-3dafd2c295f1",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e0d17-e35a-4297-a6ad-87c675083f73",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ff3a4-66c3-460b-8f3e-153c708c293c",
   "metadata": {},
   "source": [
    "## Question 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15162a6-6c22-4e90-9fba-8afdf8fddb51",
   "metadata": {},
   "source": [
    "Which of the following methods exist in the ```DictWriter``` object provided by the ```csv``` module?\n",
    "\n",
    "(Select all that apply.)\n",
    "\n",
    "a) writeseparator\n",
    "\n",
    "b) writerow\n",
    "\n",
    "c) writeheader\n",
    "\n",
    "d) write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e41a80-8043-466b-9a6e-b5d8b5f1a81f",
   "metadata": {},
   "source": [
    "## Solution 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d932d1c-453b-4fb4-86e5-d1d61c317511",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e9b38-e2a9-4602-8b66-8a9f7ad25454",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe36424-e076-4449-9b12-2a64b2519faa",
   "metadata": {},
   "source": [
    "## Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699415d9-b309-4520-a994-ad4b7bd3df89",
   "metadata": {},
   "source": [
    "Select the XML modules available in the Python standard library:\n",
    "\n",
    "(Select all that apply)\n",
    "\n",
    "a) xml.parser\n",
    "\n",
    "b) xml.etree.ElementTree\n",
    "\n",
    "c) xml.processor\n",
    "\n",
    "d) xml.dom.minidom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6a562-2f59-43e4-ba00-033d38f2ff39",
   "metadata": {},
   "source": [
    "## Solution 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabf1ae-f342-414c-a55b-f35805d731e8",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c97b5-d64f-4b12-982c-8de68d9e882d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31304d5e-af08-4d67-8adb-6ababfff1c17",
   "metadata": {},
   "source": [
    "## Question 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a309152-c2d6-4799-b56f-10bb9d849ddc",
   "metadata": {},
   "source": [
    "In the csv module, reading data from a csv file is possible using:\n",
    "\n",
    "(Select all that apply)\n",
    "\n",
    "a) the ```reader``` function\n",
    "\n",
    "b) the ```CsvReader``` class\n",
    "\n",
    "c) the ```DictReader``` class\n",
    "\n",
    "d) the ```read_csv``` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331a9ac-ada3-4b27-884b-15169266d894",
   "metadata": {},
   "source": [
    "## Solution 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92b04d-defd-4029-9d5f-76b00d058903",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16f396-97b1-471a-b939-efb0a72d4f52",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f783ce-b0e6-4924-acfa-0170473b68ff",
   "metadata": {},
   "source": [
    "## Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ada63b-33a7-4de3-8427-5aaaa32edb57",
   "metadata": {},
   "source": [
    "You have a dataset containing product sales information, including the product name, quantity sold, and price per unit. You need to calculate the total revenue generated from sales. Which of the following Python code snippets accomplishes this task?\n",
    "\n",
    "a) ```total_revenue = sum(product['quantity_sold'] * product['price_per_unit'] for product in products)```\n",
    "\n",
    "b) ```total_revenue = sum(product['quantity_sold'] * product['price_per_unit'] for product in products) / len(products)```\n",
    "\n",
    "c) ```total_revenue = sum(product['quantity_sold'] * product['price_per_unit'] for product in products) * len(products)```\n",
    "\n",
    "d)  ```total_revenue = sum(product['quantity_sold'] * product['price_per_unit'] / len(products) for product in products)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216b4fb-b402-4bf9-a02c-464844188465",
   "metadata": {},
   "source": [
    "## Solution 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076253a-dfd2-4487-8132-aaa3accbcb1d",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38873ac2-8794-412a-92d3-5cf2735c7da0",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55af77-959d-4b90-bb50-a4db23bd5b03",
   "metadata": {},
   "source": [
    "## Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893fdd8a-1c53-4cd9-91c4-b402ed4e60c3",
   "metadata": {},
   "source": [
    "You are working with a Python dictionary representing student grades. Which code snippet correctly accesses the grade for the student with ID “123”? \n",
    "```\n",
    "student_grades = {“123”: 85, “456”: 92, “789”: 78}\n",
    "```\n",
    "a) ```student_grades[1]```\n",
    "\n",
    "b) ```student_grades.get(\"123\")```\n",
    "\n",
    "c) ```student_grades[\"123\"]```\n",
    "\n",
    "d) ```student_grades.get(123)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4af8b-10eb-4bdd-b61e-8644e9457c05",
   "metadata": {},
   "source": [
    "## Solution 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2355428-0126-41bc-8b85-381f55b7223c",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09633118-dd1f-49ca-a487-30760c3d2e99",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72cd04d-2b35-44a3-a8b0-345c1e9f92d1",
   "metadata": {},
   "source": [
    "## Question 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10dbe0-d881-4158-8977-76447fce588a",
   "metadata": {},
   "source": [
    "You have a dictionary containing student names and their corresponding scores. You want to find the student with the highest score. Which code snippet accomplishes this task? \n",
    "\n",
    "```scores_dict = {“Alice”: 85, “Bob”: 92, “Charlie”: 78}```\n",
    "\n",
    "a) ```max(scores_dict, key=scores_dict.get)```\n",
    "\n",
    "b) ```max(scores_dict.values())```\n",
    "\n",
    "c) ```max(scores_dict.keys())```\n",
    "\n",
    "d) ```max(scores_dict.items(), key=lambda x: x[1])```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57361a61-15ce-46cd-b8b1-607649c20255",
   "metadata": {},
   "source": [
    "## Solution 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2c5c5-73aa-4adf-8899-e0fff267b004",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f187ee9-16eb-4488-b883-2dc164ece2e5",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa799c-e482-4de1-ac66-5842f2824045",
   "metadata": {},
   "source": [
    "## Question 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c318fd5-a328-4c09-a396-bb04217dba30",
   "metadata": {},
   "source": [
    "You want to create a Python function that takes two arguments, a list of numbers and a target value, and returns True if the target value is present in the list and False otherwise. Which code snippet defines this function correctly?\n",
    "\n",
    "a) \n",
    "```\n",
    "def check_target_value(lst, target):\n",
    "    return target in lst\n",
    "```\n",
    "\n",
    "b) \n",
    "```\n",
    "def check_target_value(lst, target):\n",
    "    if target in lst:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "```\n",
    "\n",
    "c)\n",
    "```\n",
    "def check_target_value(lst, target):\n",
    "    if target == lst:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "```\n",
    "\n",
    "d)\n",
    "```\n",
    "def check_target_value(lst, target):\n",
    "    for num in lst:\n",
    "        if num == target:\n",
    "            return True\n",
    "        return False  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a99a1-505a-4886-9b5f-28c0fc40490a",
   "metadata": {},
   "source": [
    "## Solution 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30247ee5-e98d-4b67-9db9-cc63e5677a6e",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271df3d1-f695-40d1-b587-c3e372dd2fd3",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910957c3-8258-499e-bb56-e87c7cdf4c06",
   "metadata": {},
   "source": [
    "## Question 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fe75a-ffb5-4031-ab0f-b1f506cccb0b",
   "metadata": {},
   "source": [
    "You have a Python script that processes a large dataset and performs multiple calculations. However, you notice that the script is running slower than expected, especially when handling large files. What is a recommended approach for optimizing the script’s performance?\n",
    "\n",
    "a) Add more comments and documentation to the script for better readability.\n",
    "\n",
    "b) Use built-in Python functions and libraries optimazed for handling large dataset.\n",
    "\n",
    "c) Break down complex calculations into smaller, manageable functions for better performance.\n",
    "\n",
    "d) Increase the size of the dataset to test the script's scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10756f-714d-4c45-9851-b8c9c2dbcd98",
   "metadata": {},
   "source": [
    "## Solution 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfacd4-c490-4a57-a604-2ab79a80742b",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ee800-294b-4485-8513-7f8279a0cf36",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca817f4-dcc8-4add-bc70-b637b7dae877",
   "metadata": {},
   "source": [
    "## Question 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c09cd-5754-4153-b899-626fdd4e8345",
   "metadata": {},
   "source": [
    "You are working on a Python script to parse and extract information from multiple JSON files in a directory. The script needs to be easily maintainable and scalable for handling new JSON files in the future. What is a recommended best practice for achieving these objectives?\n",
    "\n",
    "a) Write a single monolithic script that processes all JSON files in the directory.\n",
    "\n",
    "b) Use modular programming by diciding the script in to functions and modules for different tasks.\n",
    "\n",
    "c) Hard-code file paths and names in the script for direct file access.\n",
    "\n",
    "d) Avoid using error handling mechanisms to keep the script concise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed200446-6042-4219-a6b5-6b882bb267f4",
   "metadata": {},
   "source": [
    "## Solution 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acc3a0-d64f-4f8a-867e-02090ca76f3f",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da6f754-52df-4807-bdb6-51b9b9a44a2e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f5144-7000-4b3f-bc3d-3b6206d015ad",
   "metadata": {},
   "source": [
    "## Question 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c14e06-9ba0-4453-9640-c298a6281a47",
   "metadata": {},
   "source": [
    "You are debugging a Python script that is supposed to extract specific information from a JSON file but encounters errors during execution. Which approach is most effective for identifying and fixing these errors?\n",
    "\n",
    "a) Rewrite the entire script using a different programming paradigm for better error handling.\n",
    "\n",
    "b) Utilize try-except blocks to catch and handle specific exceptions that occur during script execution.\n",
    "\n",
    "c) Increase the script's memory allocation to prevent runtime errors related to memory exhaustion.\n",
    "\n",
    "d) Ignore the errors and proceed with running the script to see if it resolvers itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8d1c3-f2c9-4c08-a417-3aa4f70d5f5e",
   "metadata": {},
   "source": [
    "## Solution 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77798591-d3a6-4636-a713-8e8b41131b1b",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84b38d-6e10-4e8b-bf97-721b5f7280f8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66232c5d-9c09-4ec4-957d-5c644028b8ed",
   "metadata": {},
   "source": [
    "## Question 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fafd58-fa52-4fca-9bb8-41ba773fbb7e",
   "metadata": {},
   "source": [
    "You've noticed that a Python script for data analysis is performing poorly and consuming a lot of memory. What would be the best approach to identify the root cause of the memory issue?\n",
    "\n",
    "a) Re-write the entire script\n",
    "\n",
    "b) Add more RAM to the system.\n",
    "\n",
    "c) Use memory profilers to pinpoint memory-consuming operations.\n",
    "\n",
    "d) Switch to a more powerful CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba1ab6-8891-4cb7-b7cd-ec904c522b16",
   "metadata": {},
   "source": [
    "## Solution 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cce7d-145e-48c1-8aed-fdf72ecc6c03",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ea306-d0b7-4cad-849c-a6f3ff1e19af",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc9670-7e89-447b-a3d7-14dd908e6b6a",
   "metadata": {},
   "source": [
    "## Question 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33915d-5b00-48f7-b6f6-1927df34b15b",
   "metadata": {},
   "source": [
    "You've written a Python script for data analysis, but it's running slower than expected. Which of the following is the best first step to take in optimizing the performance?\n",
    "\n",
    "a) Convert the script to a lower-level language like C.\n",
    "\n",
    "b) Refactor the code to use multithreading.\n",
    "\n",
    "c) Increase the hardware resources (CPU, RAM).\n",
    "\n",
    "d) Profile the code to identify bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77288379-b6b4-414d-84f6-83a755d54e37",
   "metadata": {},
   "source": [
    "## Solution 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8ca2a-97c0-455e-90a8-d308ad2843fd",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b82050-59f8-4331-8923-41732eacb046",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9816bf-abcd-498a-a8e9-cbba8311b99c",
   "metadata": {},
   "source": [
    "## Question 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40424f-ab50-4d0e-bf73-2aa45467c510",
   "metadata": {},
   "source": [
    "Which of the following best describes the practice of \"version control\" in the context of data scripting?\n",
    "\n",
    "a) Update the Python interpreter regularly.\n",
    "\n",
    "b) Use Git or another VCS to keep track of changes in your scripts.\n",
    "\n",
    "c) Use comments in your code to describe changes made in different versions.\n",
    "\n",
    "d) Always keep a backup copy of your original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5193b-93d9-4e0f-b7bd-120f8a5c6d3b",
   "metadata": {},
   "source": [
    "## Solution 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d38ff-6061-4213-94e8-7da24ce4d3f5",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcb4d7-36f2-47bf-9618-dcca2b1811b5",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24686e-01e7-4ba8-961f-7bdc067276d1",
   "metadata": {},
   "source": [
    "## Question 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959092f-4c10-4f45-b280-d040e53b9686",
   "metadata": {},
   "source": [
    "You are tasked with creating a Python function that reads data from an SQLite database and returns it as a Pandas DataFrame. Which of the following implementations is correct?\n",
    "\n",
    "a)\n",
    "```\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def read_sqlite_to_df(database_path, query):\n",
    "    con = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    return df\n",
    "```\n",
    "\n",
    "b)\n",
    "```\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def read_sqlite_to_df(database_path, query):\n",
    "    con = sqlite3.connect(database_path)\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(query)\n",
    "    df = cursor.fecth_pandas()\n",
    "    con.close()\n",
    "    return df\n",
    "```\n",
    "\n",
    "c) \n",
    "```\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def read_sqlite_to_df(database_path, query):\n",
    "    con = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    return df\n",
    "```\n",
    "\n",
    "d)\n",
    "```\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def read_sqlite_to_df(database_path, query):\n",
    "    con = sqlite3.connect(database_path)\n",
    "    df = pd.read_dataframe(query)\n",
    "    con.close()\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c8261-008b-40bb-b4b7-1ce355f5b480",
   "metadata": {},
   "source": [
    "## Solution 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb55e1-db29-4c7d-a399-a08d7f2d6712",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbfd90-6f28-44e6-88f8-f19692d58179",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3eeb3-bd6e-428a-ad3b-c2e68dc8f680",
   "metadata": {},
   "source": [
    "## Question 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7f4f0-5db2-49dc-90fe-77adbf6de46b",
   "metadata": {},
   "source": [
    "When integrating time-series data from multiple sensors into a single dataset, what is essential to ensure data consistency and accuracy?\n",
    "\n",
    "a) Aligning all data entries to the same time scale and format.\n",
    "\n",
    "b) Focusing on the sensor with the highest frequency of data collection.\n",
    "\n",
    "c) Summarizing the data from each sensor before merging to reduce complexity.\n",
    "\n",
    "d) Chossing one sensor as the primary source and discarding data from others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d729af-34ce-492d-9da4-d10db7dffd2c",
   "metadata": {},
   "source": [
    "## Solution 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18baa0b-f0e2-40e3-8324-0b8c47c03e21",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d01b3-3bc6-41e1-8b83-03ab2e426fbe",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598cc2f1-ac6d-4515-a99d-0d141cca0e5f",
   "metadata": {},
   "source": [
    "## Question 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d47533-c79f-44e1-9512-068e2dd2af11",
   "metadata": {},
   "source": [
    "In a dataset containing customer phone numbers, which data validation technique is most suitable for ensuring the reliability and accuracy of phone numbers?\n",
    "\n",
    "a) Pattern validation\n",
    "\n",
    "b) Completeness validation\n",
    "\n",
    "c) Consistency validation.\n",
    "\n",
    "d) Format validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a434636-abec-4211-85cf-0f78237463df",
   "metadata": {},
   "source": [
    "## Solution 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e3fe1-4a09-4308-bedb-fa323d6a426a",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b368115-040f-4aa2-a164-a2030f665891",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06048c04-23ad-437d-8261-4f2a795d4de9",
   "metadata": {},
   "source": [
    "## Question 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ae835-8db9-46e4-a007-f651e8c97233",
   "metadata": {},
   "source": [
    "You are working with a dataset that contains outliers in the “Temperature” column, affecting the statistical analysis. What method would you use to detect and handle these outliers?\n",
    "\n",
    "a) Z-score method\n",
    "\n",
    "b) Interquartile range (IQR)\n",
    "\n",
    "c) Standard deviation method\n",
    "\n",
    "d) To define the syntax and structure of the Python language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df82e97-d287-48ea-aceb-f3b9fa846217",
   "metadata": {},
   "source": [
    "## Solution 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fe410-048a-4118-90ac-b4cf6d07169d",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d67011-e25d-4918-b886-131d5d34cd50",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f67bc7-c06a-4816-b1d5-d46a42fe8376",
   "metadata": {},
   "source": [
    "## Question 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742a738-14d6-4a39-b50a-3c049083d79b",
   "metadata": {},
   "source": [
    "You are tasked with merging two datasets, df1 and df2, on a common column 'id'. df1 has a column 'value1' and df2 has a column 'value2'. After merging, you need to create a new column called 'total_value' that sums 'value1' and 'value2'. Which of the following code snippets accomplishes this?\n",
    "\n",
    "a)\n",
    "```\n",
    "df_merged = pd.merge(df1, df2, on='id')\n",
    "df_merged['total_value'] = df_merged['value1'] + df_merged['value2']\n",
    "```\n",
    "\n",
    "b)\n",
    "```\n",
    "df_merged = df1.join(df2, on='id')\n",
    "df_merged['total_value'] = df_merged['value1'] + df_merged['value2']\n",
    "```\n",
    "\n",
    "c)\n",
    "```\n",
    "df_merged = pd.concat([df1, df2], keys='id')\n",
    "df_merged['total_value'] = df_merged['value1'] + df_merged['value2']\n",
    "```\n",
    "\n",
    "d)\n",
    "```\n",
    "df_merged = df1.merge(df2)\n",
    "df_merged['total_value'] = df_merged['value1'] + df_merged['value2']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da13f2-327e-4d94-83d9-510f4b06e196",
   "metadata": {},
   "source": [
    "## Solution 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69daff6c-616a-40cd-b5f2-f105e1473939",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffb981-83e7-48e2-88fd-f35ec8538160",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1409d5b7-903d-4d3a-8cca-e1265331acaa",
   "metadata": {},
   "source": [
    "## Question 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a1878e-87d7-4f05-b106-e3a1d60834f5",
   "metadata": {},
   "source": [
    "You are working on preprocessing a dataset for a classification problem. You notice that one of the numerical features has a heavily skewed distribution. Which of the following transformations is least likely to help in handling the skewness?\n",
    "\n",
    "a) Z-score normalization\n",
    "\n",
    "b) Box-Cox transformation\n",
    "\n",
    "c) Logarithmic transformation\n",
    "\n",
    "d) Square root transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf47f04-d8a8-4e52-9e0d-140561cf0289",
   "metadata": {},
   "source": [
    "## Solution 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f28e30-8088-48cd-9625-a89e2a53e131",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713dfc30-4568-4d00-a6e9-097fc3349afa",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f6493-0613-4ece-a595-25914f4e6c69",
   "metadata": {},
   "source": [
    "## Question 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c4958-d5a0-4b09-ad78-e3dfbfa7a0bf",
   "metadata": {},
   "source": [
    "You are working on a Python project using pandas and have loaded a DataFrame from a CSV file. The DataFrame has columns named ID, Name, Salary, and Age. After conducting an initial examination, you notice that the Salary column contains some NaN values. What is the most effective way to replace these NaN values with the mean salary without affecting the other columns?\n",
    "\n",
    "a) `df['Salary'].fillna(df['Salary'].mean(), implace=True)`\n",
    "\n",
    "b) `df['Salary'].fillna(df['Salary'].average(), implace=True)`\n",
    "\n",
    "c) `df.fillna(df.mean(), axis='Salary')`\n",
    "\n",
    "d)  `df['Salary'].fillna(df['Salary'].mean())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d196f1-68d6-47f0-af93-d76399e381a5",
   "metadata": {},
   "source": [
    "## Solution 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d376d-04b7-4854-b534-d2fcd0c49532",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26039b5c-334b-4cad-adf8-a14253a8d256",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a2660-c353-4954-bd2b-ca70669b0124",
   "metadata": {},
   "source": [
    "## Question 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df52546-035d-45f3-9b4a-8c802baf675c",
   "metadata": {},
   "source": [
    "Consider the following Python code snippet that uses Pandas:\n",
    "\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    " \n",
    "data = {\n",
    "    'Department': ['HR', 'HR', 'Engineering', 'Engineering', 'Marketing'],\n",
    "    'Salary': [50000, 60000, 80000, 90000, 70000]\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    "grouped = df.groupby('Department').agg({'Salary': 'mean'})\n",
    "result = grouped.loc['Engineering', 'Salary']\n",
    "```\n",
    "\n",
    "What will be the value of result after executing the code?\n",
    "\n",
    "a) 85000\n",
    "\n",
    "b) 75000\n",
    "\n",
    "c) 80000\n",
    "\n",
    "d) 70000\n",
    "\n",
    "e) 90000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3242b-00ee-4cfe-a9cd-28460909f425",
   "metadata": {},
   "source": [
    "## Solution 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2433f3-5a35-4298-9ca4-986faad4a38e",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a984e00-68e8-4878-9598-4fdd93a01e47",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d577a6-30cc-453f-9c1d-84b3f25e87b6",
   "metadata": {},
   "source": [
    "## Question 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724a90-bfb1-419f-89df-b845657eeb3b",
   "metadata": {},
   "source": [
    "You are building a classification model using Scikit-learn and want to split your dataset into training and testing sets. Which code snippet correctly performs this task assuming X contains feature data and y contains target labels? from sklearn.model_selection import train_test_split\n",
    "\n",
    "a) `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`\n",
    "\n",
    "b) `X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`\n",
    "\n",
    "c) `X_train, X_test= train_test_split(X, y, test_size=0.2, random_state=42), y_train, y_test`\n",
    "\n",
    "d) `X_train, y_train= train_test_split(X, y, test_size=0.2, random_state=42), X_test, y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25ca96-7e86-4de4-9893-77db5aa85aae",
   "metadata": {},
   "source": [
    "## Solution 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db32f93-327e-4188-97d3-a66f9fad92d0",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b3290-6f6f-48ef-b498-4dd9c849729d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a55190-559e-487b-95db-5bf68adf5c79",
   "metadata": {},
   "source": [
    "## Question 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30369a-a45b-4781-97e3-fc57738fdc1d",
   "metadata": {},
   "source": [
    "When using Python to clean data, what is the correct way to replace all occurrences of a specific value in a pandas DataFrame with another value?\n",
    "\n",
    "a) `df.replace('old_value', 'new_value')`\n",
    "\n",
    "b) `df.update('old_value', 'new_value')`\n",
    "\n",
    "c) `df.set_value('old_value', 'new_value')`\n",
    "\n",
    "d) `df.modify('old_value', 'new_value')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c45968-4422-4b05-a470-d78603162262",
   "metadata": {},
   "source": [
    "## Solution 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085f2ac-016c-4cfb-a886-6670f665d132",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe6386-dc6e-44d5-975b-08327024f54f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14f974-8d91-415e-b14d-02790f51764c",
   "metadata": {},
   "source": [
    "## Question 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7fe84-a211-472c-9e43-c124f330d4fc",
   "metadata": {},
   "source": [
    "You are analyzing data related to annual rainfall and temperature for various cities. You want to show the relationship between rainfall and temperature for each city, as well as highlight the cities with the most and least rainfall. Which type of visualization would be most effective for this scenario?\n",
    "\n",
    "a) Bar Graph\n",
    "\n",
    "b) Scatter Plot with Color Coding\n",
    "\n",
    "c) Line Graph\n",
    "\n",
    "d) Pie chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35679f4-13ad-45bd-b71a-ace867cee9a2",
   "metadata": {},
   "source": [
    "## Solution 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97cbe8a-a90d-4105-bdd4-e94174163c12",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a325d-f744-44ce-b914-bbba0343d1f8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0df00-a475-435f-bc94-85d6d309a6d9",
   "metadata": {},
   "source": [
    "## Question 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd826a-e02d-4ea1-95c3-2f064e950efa",
   "metadata": {},
   "source": [
    "You are required to present a comparative analysis of the sales data of five different products over the last year. What would be the most effective way to visualize this data?\n",
    "\n",
    "a) Heatmap\n",
    "\n",
    "b) Multiple Line Graphs on the same plot\n",
    "\n",
    "c) 3D Surface Plot\n",
    "\n",
    "d) Radar Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a61b1-9473-4250-b873-99190af84c90",
   "metadata": {},
   "source": [
    "## Solution 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc60ce8-73d0-4c4b-bf47-330d7bb0d681",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d2e2e-5e72-475b-8dbb-83e716fcfa25",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cbb59-be51-4309-9096-d0c6a67c41b8",
   "metadata": {},
   "source": [
    "## Question 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132d0e7-614f-4f00-a1fa-383d02cc4019",
   "metadata": {},
   "source": [
    "You are tasked with visualizing a dataset containing the frequency distribution of student grades ('A', 'B', 'C', 'D', 'F') in a classroom. What is the most appropriate type of visualization to use?\n",
    "\n",
    "a) Polar Plot\n",
    "\n",
    "b) Bar Chart\n",
    "\n",
    "c) Heatmap\n",
    "\n",
    "d) Line Plot\n",
    "\n",
    "e) 3D Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063506f3-5a95-472e-9196-43ae15282308",
   "metadata": {},
   "source": [
    "## Solution 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae62e7-43dd-4433-a7f1-d4b6a71da907",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8a544-8eca-499d-9ecb-18198f241c5b",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb6b08-d6bd-4f7c-8200-04b840277302",
   "metadata": {},
   "source": [
    "## Question 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b5112-a7ef-47a0-9273-c2dff0aca7f2",
   "metadata": {},
   "source": [
    "You are working on a Python script to validate user inputs in a survey form. The survey includes a field for the email address. What would be the most robust way to validate the email addresses?\n",
    "\n",
    "a) Use a regular expression to match the pattern of a valid email address.\n",
    "\n",
    "b) Automatically accept any input in the email field and flag them for later review.\n",
    "\n",
    "c) Use the ```len()``` function to check if the email address exceeds a certain length.\n",
    "\n",
    "d) Use Python's ```input()``` funtion's validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80ec2d-4c43-41fe-b2ae-b3ded81596df",
   "metadata": {},
   "source": [
    "## Solution 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede252b-45b8-4da4-a097-a7be42f30bf4",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfa9ff-d4b1-4df4-aa27-f9249c31872b",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f86d7-5530-462b-8d22-cdaebb3282d9",
   "metadata": {},
   "source": [
    "## Question 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f3f61-5af3-4088-bddc-f71506fe4298",
   "metadata": {},
   "source": [
    "You are working with a dataset that contains sales data for 50 products over a span of 12 months. You want to visualize how the sales of each product have changed over time. The emphasis is on understanding trends and spotting outliers. Which of the following visualization techniques would best serve your purpose?\n",
    "\n",
    "a) Heatmap\n",
    "\n",
    "b) Small Multiple (Facet Grids)\n",
    "\n",
    "c) Candlestick Chart\n",
    "\n",
    "d) Box Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6fc8a1-0fa7-4510-bdce-54180dd1f668",
   "metadata": {},
   "source": [
    "## Solution 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5111d2-a3b5-4b4a-b3ef-87b49dfb89af",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0b230-89f3-4213-9da0-445da5b3bfa6",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15868d59-612d-4663-b9e2-e1f28cedbcf2",
   "metadata": {},
   "source": [
    "## Question 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7f896-3ca2-4309-a871-6d77808e791b",
   "metadata": {},
   "source": [
    "When dealing with a skewed numerical feature, which of the following transformation techniques is least likely to normalize the distribution of the feature?\n",
    "\n",
    "a) Logarithmic transformation\n",
    "\n",
    "b) Quantile transformation\n",
    "\n",
    "c) Z-score normalization\n",
    "\n",
    "d) Box-Cox transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2206b5-2939-42cc-a142-feff11944a8c",
   "metadata": {},
   "source": [
    "## Solution 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c3eec-8886-4b82-8b80-3d4ce8e84d6d",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2569f-8006-4bf4-80e1-ce0c3ff0a3f1",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169fafa-4c34-46d4-b678-785faae08a8c",
   "metadata": {},
   "source": [
    "## Question 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c390a4-86e6-4877-83c3-d09080b21a17",
   "metadata": {},
   "source": [
    "When designing an interactive dashboard, what should be the primary focus to enhance user experience?\n",
    "\n",
    "a) Adding as many widgets as possible.\n",
    "\n",
    "b) Using complex and intricate visualizations.\n",
    "\n",
    "c) Using a wide range of contrasting colors.\n",
    "\n",
    "d) Focusing on quick load times and responsive design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f956af-234f-49cb-8842-d38ce8478025",
   "metadata": {},
   "source": [
    "## Solution 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76dd4a-468b-426f-b960-e285b13cba26",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856893a-129b-43c2-ac51-f887f494d195",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ec54e-f7b7-4e34-b5f7-da296b85e600",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
