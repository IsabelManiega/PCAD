{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2541b22e-92ab-443f-84a8-e48a34761aaa",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d204d-5d12-4227-807a-c16cb2be401d",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90014ce0-2ef9-422a-8488-0ab42a8a3b04",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367736f-32c1-4ed9-8807-7d4f1b9c6916",
   "metadata": {},
   "source": [
    "```\n",
    "Patricia is analyzing consumer trends in the fashion industry. \n",
    "She needs to collect data on the types of clothing items that are currently popular. \n",
    "Which method should Patricia use to gather this information?\n",
    "\n",
    "a) Conducting in-deph interviews with fashion designers.\n",
    "b) Analyzing sales data from major retail fashion stores.\n",
    "c) Surveying consumers on their recent clothing purchases.\n",
    "d) Reviewing fashion magazines and trend reports.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d6332-582e-4165-a9d7-6865b861665e",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc5719-6d70-410e-bdd3-14854c60ed87",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827feb1-f9a2-40e1-b810-03d9c2e63da0",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d7098-f1c0-4874-ada2-6dccfacd762f",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ef3f0-ed64-44cf-b2f7-d4ac816831f6",
   "metadata": {},
   "source": [
    " You’re responsible for presenting the quarterly performance of your company's social media channels to a group of executives with limited technical knowledge. The key metrics include Total Followers, Engagement Rate, and Click-Through Rate. Here’s the performance data for the year:\n",
    "\n",
    "|    Quater   | Total Followers | Engagement Rate (%) | Clicks-Through Rate (%) |\n",
    "|-------------|-----------------|---------------------|-------------------------|\n",
    "| Q1 (Jan-Mar)|    20000        |       5.0           |          2.5            |\n",
    "| Q2 (Apr-Jun)|    23500        |       6.0           |          3.0            |\n",
    "| Q3 (Jul-Sep)|    27000        |       6.5           |          3.5            |\n",
    "| Q4 (Oct-Dec)|    30000        |       7.0           |          3.8            |\n",
    "\n",
    "How should you present this data to ensure clear understanding and actionable insights for your non-technical audience, especially focusing on the distribution and variability of the data? Select the best approach.\n",
    "\n",
    "a) Use box plots to display the distribution and variability of Total Followers, engagement Rate, and Click-Through Rate for each quarter,paired with clear explanations to help the audience understand the central tendency, spread and outliers in the data.\n",
    "\n",
    "b) Use a detailed spreadsheet format in the presentation that shows every metric's quarterly data, expecting stakeholders to draw conclusions on their own, demostrating the complexity of the data.\n",
    "\n",
    "c) Create a complex infographic that combines all metrics using advanced visualizations and technical jargon, assuming the intricate design will impress and engage the executive.\n",
    "\n",
    "d) Utilize simple line and bar graphs to display trends in Total Followers, Engagement Rate, and Click-Trough Rate, paired with brief explanations that provide context and highlight key takeaways, ensuring the data is easy to understand and actionable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45aa8c-e648-4300-8326-d0a78b423420",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca7c15-0134-4db3-b681-a7c8feb6c098",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a959d-12b9-4c2e-b2bc-1674e54567c4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5020d9b-2fdb-4119-8e36-96f05abfb56b",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d23e3-6e56-4e74-8884-1bae397351af",
   "metadata": {},
   "source": [
    "```\n",
    "Sophia is tasked with combining quarterly financial data from different departments into a single report.\n",
    "To ensure data accuracy and consistency, what is the most important step Sophia should take?\n",
    "\n",
    "a) Prioritize data from the department with the hihest revenue.\n",
    "b) Standardize numerical formats and check for discrepancies in departmental data before merging.\n",
    "c) Merge all data first and then address any discrepancies afterward.\n",
    "d) Use the most recent quarter's data template for all department.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb550743-ae07-49ad-a914-428ec493319e",
   "metadata": {},
   "source": [
    "## Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e3076-3477-4e10-9c19-f23fe1534852",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2357d3-48a6-4e89-8485-5b1ef0f32dd2",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745584b-85c5-43af-8f11-46dc5666ea15",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d08da-ce99-4249-bba7-6b9f59f27602",
   "metadata": {},
   "source": [
    "You conducted a study and calculated a 95% confidence interval for the mean difference between two groups as (2, 8). What does this confidence interval indicate?\n",
    "\n",
    "a) The true mean difference between the two groups is likely between 2 and 8.\n",
    "\n",
    "b) The true mean difference the two groups is exactly 2.\n",
    "\n",
    "c) There is a 95% chance that the true mean difference is between 2 and 8.\n",
    "\n",
    "d) The study results are inconclusive about the mean difference between the two groups,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53335641-3fc2-4657-acf9-2a650f928ec5",
   "metadata": {},
   "source": [
    "## Solution 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80e578-ee1e-4397-a33b-45253a3177c9",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051716c-fd63-4f78-83b4-a849ab9d9178",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a62d8-a19f-41fc-90d7-5da15bb57fac",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d6ccb-dce7-4f44-ab76-e8cc190d2863",
   "metadata": {},
   "source": [
    "```\n",
    "Michael is studying the migration patterns of birds in a coastal area. \n",
    "He needs to collect data on the number of different bird species present throughout the year. \n",
    "What method should Michael employ to collect this data?\n",
    "\n",
    "a) Reviewing literature on bird migration patterns.\n",
    "b) Using autommated cameras to record bird movements.\n",
    "c) Conducting monthly surveys through direct observation.\n",
    "d) Analyzing satellite images of the area.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6d418-3f8b-44a7-8a74-bcb00b9ec7dc",
   "metadata": {},
   "source": [
    "## Solution 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75031f-cc45-4a80-90cb-2b2bafb72588",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8b5f7-7327-43c8-aba7-d627c1fd3c81",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ddb2e-1160-4ad4-a623-9594823680b3",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f87b1-c2c3-47f1-abb7-dea44071d9fa",
   "metadata": {},
   "source": [
    "```\n",
    "A dataset contains dates of customer transactions, and some dates are listed as ’31st February’. What type of data issue do these entries represent?\n",
    "\n",
    "a) Incomplete data, as the year is not specified.\n",
    "b) Irrelevant data, as the date may not be needed for analysis.\n",
    "c) Erroneous data, due to an impossible date.\n",
    "d) Duplicate data, if the same incorrect date appears multiple times.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2091e71-1f53-43bc-88d4-3007da96701e",
   "metadata": {},
   "source": [
    "## Solution 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2efe9b-538a-4831-a71d-b8d877110a99",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ee8ab-728a-4d35-b2c2-ade863073422",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6f801-a940-4cbb-bc27-d337366c23df",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce199d4-463b-423c-9935-db9f5d5eaa1d",
   "metadata": {},
   "source": [
    "You are working with a Pandas DataFrame df containing a column named Scores with student scores ranging from 0 to 100. You want to normalize these scores to lie in the range of [0, 1]. Which of the following lines of code will accomplish this task correctly?\n",
    "\n",
    "a) ```df['Scores'] = df['Scores'] / df['Scores'].max()```\n",
    "\n",
    "b) ```df['Scores'] = df['Scores'] / 100```\n",
    "\n",
    "c) ```df['Scores'] = df['Scores'] - df['Scores'].min()) / df['Scores'].max()```\n",
    "\n",
    "d) ```df['Scores'] = df['Scores'].apply(lambda x : (x-df['Scores'].min()) / (df['Scores'].max() - df['Scores'].min()))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e30a01-9a51-41da-bd31-e7e9a9b7f899",
   "metadata": {},
   "source": [
    "## Solution 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa10d3-94b3-40d7-a903-e20fea873dd2",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76a161-0cb3-4881-ab69-f960175b7179",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d40df-f87e-4099-be9e-92604116d408",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc94b7b-61a6-4c54-bc01-d53792594076",
   "metadata": {},
   "source": [
    "```\n",
    "In cleaning a dataset for a health study, a data analyst notices several instances where the ‘age’ column contains values over 150 years. \n",
    "How should these data points be treated?\n",
    "\n",
    "a) As incomplete data, because the exact ages are not known.\n",
    "b) As valid data, considering potential recording errors.\n",
    "c) As erroneous data, given the unrealistic age values.\n",
    "d) As duplicated data, if the same age appears multiple times.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d59ba1-5f5a-47a0-a540-e2a333d33651",
   "metadata": {},
   "source": [
    "## Solution 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba5d82-6cef-4cba-9330-fb77891722c0",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36d68d-f09a-4fa3-9300-71fe99ca475f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e6ff4-b432-43e1-985b-55b1a6b7f8f2",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f897fc6-b986-4c2b-81df-f910444e3398",
   "metadata": {},
   "source": [
    "```\n",
    "When integrating time-series data from multiple sensors into a single dataset, what is essential to ensure data consistency and accuracy?\n",
    "\n",
    "a) Aligning all data entries to same time scale and format.\n",
    "b) Focusing on the sensor with the highest frequency of data collection.\n",
    "c) Summarizing the data from each sensor before merging to reduce complexity.\n",
    "d) Choosing one sensor as the primary source and discarding data from others.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3729e4-8dac-4366-8c65-0fc19e6c20f3",
   "metadata": {},
   "source": [
    "## Solution 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbaaa5-2e72-495e-a955-8536b811a55a",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57615593-10af-4951-91f9-8439a07300fd",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9586bcf-2840-46d8-be8e-ad5977421aad",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5596f-1222-4035-9c4c-0b02cf4f8540",
   "metadata": {},
   "source": [
    "```\n",
    "Alex is integrating user interaction data from a website and a mobile app to analyze overall user behavior. What should Alex do to ensure the integration is valid and the data is comparable?\n",
    "\n",
    "a) Aggregate all data points into a single average value for simplicity.\n",
    "b) Validate and align interaction metrics from both sources to ensure they are on a similar.\n",
    "c) Focus only on the platform with more user interactions for a biased analysis.\n",
    "d) Manually enter website data to match the volume of app data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a94e91-c104-4a88-9dcc-af205203369b",
   "metadata": {},
   "source": [
    "## Solution 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e70b9-e86f-4a65-a67e-9b7717cfbece",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9ca1b-5e05-49cb-afbc-58d008da3f85",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e088103-1b99-4025-8745-79b8e3d56f7b",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d50761-5bd5-443e-90fb-59453801a896",
   "metadata": {},
   "source": [
    "```\n",
    "You have conducted a survey on customer satisfaction and created a visualization showing the overall satisfaction levels across different demographics. How would you effectively communicate the insights from this visualization to a technical audience?\n",
    "\n",
    "a) Avoid discussing the methodology and focus on the general trends.\n",
    "b) Provide a high-level summary with key statistical metrics.\n",
    "c) Present detailed analysis including survey methodology and statistical significance.\n",
    "d) Use visual metaphors and analogies to explain the satisfaction levels.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82843c-4acf-49ff-9e6a-b55d68fd4713",
   "metadata": {},
   "source": [
    "## Solution 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c1dcb-9bc9-4ed7-8b0c-66f81016c005",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4114f3b4-d80f-4fee-a668-b93e4fd8bd4f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b931a7e-7c2b-44fb-8d29-07bcd174b9ff",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa712314-7d49-4e66-a9ac-1584a8910a80",
   "metadata": {},
   "source": [
    "```\n",
    "You have analyzed sales data for a retail company and created a visualization showing the revenue trends for different product categories over the past year. How would you effectively communicate the insights from this visualization to a non-technical audience?\n",
    "\n",
    "a) Present complex statistical analysis with technical jargon.\n",
    "b) Use clear and concise labels on the visualization to highlight key trends.\n",
    "c) Provide raw data and detailed charts for audience exploration.\n",
    "d) Use advanced machine learning algorithms to explain the revenue trends.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c44008-5b57-4402-b1f1-c7535d138850",
   "metadata": {},
   "source": [
    "## Solution 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976568f-1fe0-4d64-b783-22d4933ed9a9",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871833b7-9587-4bb1-96cb-48568b9c1f43",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8385d-b2b4-49bc-a626-fb423f397809",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad9a17-c1e3-47c2-b9ff-9f277552bc99",
   "metadata": {},
   "source": [
    "```\n",
    "You are developing a Python script to process a large dataset and perform various data manipulations. Which of the following coding practices is considered a best practice for improving script maintainability?\n",
    "\n",
    "a) Using single-letter variable names for improved readability.\n",
    "b) Writing long and complex functions to minimize the number of lines.\n",
    "c) Adding descriptive comments to explain the purpose of each function and major code sections.\n",
    "d) Using global variables extensively to avoid passing arguments between functions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601ff34-b03c-4e7f-9f66-5a12fe61e27f",
   "metadata": {},
   "source": [
    "## Solution 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8c9c8-7d6a-481a-90ad-a668ecef0b83",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dffd9e-73e3-4e6a-a89f-895b5fcb186a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb7b11-59ac-4b29-bb3d-7fd326fd5298",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6cf09b-d836-4087-ab63-ad819743772b",
   "metadata": {},
   "source": [
    "```\n",
    "You have analyzed website traffic data and created a visualization showing the user engagement metrics over time. How would you effectively communicate the insights from this visualization to a non-technical audience?\n",
    "\n",
    "a) Use technical terms and metrics without explanation.\n",
    "b) Create a narrative around user behavior patterns and trends.\n",
    "c) Provide raw data and detailed charts for audience exploration.\n",
    "d) Focus on the aesthetics of the visualization rather than the insights.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd296b-4b24-4172-964a-1d6bc25b4b11",
   "metadata": {},
   "source": [
    "## Solution 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437b74b-052d-4da8-821c-ebe39b3e81d1",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abab50-2771-4145-aabe-93a1e77a068a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93b694-b6b1-406d-b96d-23b46a5d6dd9",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528079e6-9665-4179-b6dd-26e3c44dfef6",
   "metadata": {},
   "source": [
    "```\n",
    "You have analyzed a dataset containing customer purchase behavior and created a visualization showing the sales trends of different product categories over time. How would you effectively communicate the insights from this visualization to a non-technical audience?\n",
    "\n",
    "a) Present detailed statistical analysis with technical terms.\n",
    "b) Use storytelling and simple language to explain the trends and patterns.\n",
    "c) Provide raw* data and complex charts for audience interpretation.\n",
    "d) Focus only on the technical aspects without context or storytelling.\n",
    "\n",
    "*raw: sin procesar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adef7cf-be2c-4a3c-b092-780e6813a951",
   "metadata": {},
   "source": [
    "## Solution 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19df203-4930-413f-9086-571d28fc6499",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a71d2d-e2e5-461e-aad4-b9e25bcf9ba4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977d141-0e18-46bb-a111-1a2f25d5cc87",
   "metadata": {},
   "source": [
    "## Question 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f2a8f-12f3-4e67-a9fd-92125084fb23",
   "metadata": {},
   "source": [
    "```\n",
    "You are analyzing the performance of an email marketing campaign. Which of the following metrics would be least indicative of the campaign's effectiveness in generating sales?\n",
    "\n",
    "a) Email Conversion Rate (Email Conversion Rate measures the perentage of recipients who take a desired action after openning an email, such as making a purchase or signing up for a service.)\n",
    "b) Time Spent on website.\n",
    "c) Email Open Rate.\n",
    "d) Bounce Rate (Bounce rate is a metric that reprensents the percentage of visitors who enter a website and then leave (\"bounce\") rather than continuing to view other pages within the same site.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375b3a6-fa13-487e-9975-386e0364b157",
   "metadata": {},
   "source": [
    "## Solution 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca0a00-95bc-43ea-b0cd-ac0b48f6d0d9",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cf80e-30d1-4169-9b69-8d08c3522240",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ba107-2f08-4e45-b95f-5794f36fe083",
   "metadata": {},
   "source": [
    "## Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354a5dc-b468-4a35-b938-61835eff68de",
   "metadata": {},
   "source": [
    "```\n",
    "In a data analysis project, you are aggregating data from various external web sources using Python. What is the most effective strategy to maintain data accuracy and integrity?\n",
    "\n",
    "a) Limit data collection to a few sources for consistency.\n",
    "b) Collect data in small batches and validate each batch.\n",
    "c) Use threading to speed up data collection.\n",
    "d) Verify data authenticity and integrity as you ingest it.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1cd1c-65c8-4dab-b385-dc2cf5c2aa1f",
   "metadata": {},
   "source": [
    "## Solution 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a17dd1-5efb-4577-a14b-d0e7aa7268c2",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60ad0c-c746-4484-ae0a-5a6a429eb264",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951109bd-6b49-416e-8882-88bd658c36be",
   "metadata": {},
   "source": [
    "## Question 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e39bb-6b30-4214-ab09-6265b833e526",
   "metadata": {},
   "source": [
    "```\n",
    "In the context of an ETL (Extract, Transform, Load) process, what is the primary purpose of the 'Extract' phase?\n",
    "\n",
    "a) Creating visualizations and reports for end-users.\n",
    "b) Retrieving and reading data from multiple heterogeneous data sources.\n",
    "c) Loading data into a data warehouse or database.\n",
    "d) Performing data cleaning and preparation for analysis.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fd3b7-5c5b-490c-83de-609194ae78e8",
   "metadata": {},
   "source": [
    "## Solution 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc55ca1-fd73-45b9-9772-1b1db10be2da",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e77e83-0be4-4ba4-ae8c-8feecef1a854",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d252213-241a-4068-b57f-b90b8a9cf98f",
   "metadata": {},
   "source": [
    "## Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f95ed9-55a3-4636-a18b-ca534bc4078a",
   "metadata": {},
   "source": [
    "```\n",
    "When developing interactive web applications using Dash, how is the concept of 'Persistence' utilized in the application's functionality?\n",
    "\n",
    "a) To constantly update the application's data in real-time.\n",
    "b) To secure the application against unauthorized access.\n",
    "c) To maintain the database connection continuosly.\n",
    "d) To remember the user's choices or data entries across multiple sessions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bc083-3fa4-4055-9e8e-8f6804748847",
   "metadata": {},
   "source": [
    "## Solution 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8471a72-cda9-4a36-89dd-8bc5efde0252",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60843b9-3f2d-46e6-8256-7c4db09901b0",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e20814-60e1-460a-a68a-b0dee707316a",
   "metadata": {},
   "source": [
    "## Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1884e-8e62-4efd-a554-4ae5cd8cf415",
   "metadata": {},
   "source": [
    "```\n",
    "You are optimizing a Python script that processes a large dataset. You notice that certain functions are being called repeatedly with the same input data, leading to redundant computations. What optimization technique should you apply to reduce redundant computations?\n",
    "\n",
    "a) Implement memoization to cache function results.\n",
    "b) Rewrite the functions to perform parallel processing.\n",
    "c) Increase the script's memory allocation for faster conputation.\n",
    "d) Add more conditional statements to skip redundant computations.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bfec7-eea9-40c0-b181-ba53673218f6",
   "metadata": {},
   "source": [
    "## Solution 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540bdc2-a722-41d8-8363-e5baa6b751aa",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa726e94-050b-403c-9814-57e9990cd10b",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fedb62-c0d1-4952-b4e8-6e327f878c3b",
   "metadata": {},
   "source": [
    "## Question 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517eaed-f97e-4b92-bd54-6031cd83b374",
   "metadata": {},
   "source": [
    "```\n",
    "You are analyzing sales data for a retail company, which includes daily sales figures for different products across multiple stores. Your goal is to generate a report that shows the total sales revenue for each product category across all stores for the entire month. What data aggregation technique is most appropriate for this task?\n",
    "\n",
    "a) Summarizing\n",
    "b) Filtering\n",
    "c) Sorting\n",
    "d) Grouping\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d369af-5943-4716-ae7b-129aac746e37",
   "metadata": {},
   "source": [
    "## Solution 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3c688-905e-43de-85cb-4949ea918e6a",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef18b4e-00a6-42d5-96c5-179f4b68959a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d648a9ad-726b-455f-ba54-5eafd192cd9d",
   "metadata": {},
   "source": [
    "## Question 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887259cc-0d1a-4987-9790-35dfb6d1a560",
   "metadata": {},
   "source": [
    "```\n",
    "You are working on a data analysis script that involves multiple data processing steps. What is a recommended best practice to ensure the script’s maintainability and readability?\n",
    "\n",
    "a) Writing all code in a single massive script for simplicity.\n",
    "b) Using short and cryptic function names to save space.\n",
    "c) Breaking down the script into smaller functions with clear and descriptive names.\n",
    "d) Embedding documentation within the script's code rather than using external documentation files.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06138c70-6ce1-4012-9262-1b976589521b",
   "metadata": {},
   "source": [
    "## Solution 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed160a-78fd-4c51-8b70-9ca04504a710",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c993d4-98a5-43e9-aa7d-75061f570165",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459218d-bab8-48d5-a1ea-5a2f1bf35611",
   "metadata": {},
   "source": [
    "## Question 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7dad0-ab56-4111-9b3c-8bfbfda08af1",
   "metadata": {},
   "source": [
    "```\n",
    "You are debugging a Python script that is producing unexpected output. After thorough examination, you suspect that the issue lies in the logic of a conditional statement. What debugging technique should you use to identify the problem?\n",
    "\n",
    "a) Add print statements to log variable values.\n",
    "b) Comment out the suspected conditional statement.\n",
    "c) Use the step-by-step debugger with breakpoint.\n",
    "d) Rewrite the contitional statement using a different syntax.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d005510-6f3c-431b-a576-1e4e0ed316c9",
   "metadata": {},
   "source": [
    "## Solution 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10249fe5-38a5-4c3d-8a18-394be93acf39",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9ac34-b7aa-43a2-b611-b394caa4ec28",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fb8f5-b838-4836-86de-7f1c804e4011",
   "metadata": {},
   "source": [
    "## Question 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b58b41-3bbf-424a-9938-442962f88a0b",
   "metadata": {},
   "source": [
    "In a dataset containing customer purchase records, which data validation technique is most suitable for ensuring the accuracy of product prices?\n",
    "\n",
    "a) Completeness validation\n",
    "\n",
    "b) Range validation.\n",
    "\n",
    "c) Consistency validation.\n",
    "\n",
    "d) Cross-reference validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb717752-18a0-439f-9eab-d1680e0b10c9",
   "metadata": {},
   "source": [
    "## Solution 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9337cee-81ad-4a5e-92f0-8e9a0dc5d240",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66f93f-3641-49be-94ad-3279789b922d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b019661-fd03-4762-bfa7-a0386ea1129b",
   "metadata": {},
   "source": [
    "## Question 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63d731-484a-4b62-a97e-75105bd0caaa",
   "metadata": {},
   "source": [
    "```\n",
    "You are working on a Python script that is running slower than expected due to inefficient code. Upon reviewing the script, you notice that a loop is repeatedly performing calculations that could be precomputed. What optimization technique should you apply to improve script performance?\n",
    "\n",
    "a) Move the loop outside the main function.\n",
    "b) Use a generator expression instead of a list comprehension.\n",
    "c) Cache the precomputed values in a dictionary.\n",
    "d) Add more nested loops for a parallel procesing.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de793b-0718-4321-8abe-f331be5b05f9",
   "metadata": {},
   "source": [
    "## Solution 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd218b6-da7c-4c71-b244-5b5e813e99cb",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c170d-73f9-4ee4-ad1a-547de588fe7a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99677f2-1960-4bd0-864f-eb9926cdc958",
   "metadata": {},
   "source": [
    "## Question 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7d9d8-1068-4d00-a4e9-57bfb11d4e7c",
   "metadata": {},
   "source": [
    "You have a DataFrame named df with the following structure:\n",
    "\n",
    "\n",
    "```\n",
    "   ID  Name  Score  Subject\n",
    "0   1   Tom     90  Math\n",
    "1   2  Lisa     85  Math\n",
    "2   1   Tom     92  History\n",
    "3   2  Lisa     88  History\n",
    "```\n",
    "\n",
    "You want to reshape this DataFrame into a format that shows scores by Subject for each individual. Which of the following code snippets will achieve this?\n",
    "\n",
    "a) ```df.pivot(index='Name', columns='Subject', values='Score')```\n",
    "\n",
    "b) ```df.groupby(['Name', 'Subject']).Score.sum().unstack()```\n",
    "\n",
    "c) ```df.pivot_table(index='Name', columns='Subject', values='Score', aggfunc='mean')```\n",
    "\n",
    "d) ```df.set_index(['Name', 'Subject']).unstack()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccefdc7-e947-4949-9bd2-e8e055d8cfdb",
   "metadata": {},
   "source": [
    "## Solution 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa2f86-9509-40dc-9569-b38f7dfce309",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c2473-aafe-4636-8af1-59e13a954954",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3472fc-2116-4add-8f82-205308b99ee4",
   "metadata": {},
   "source": [
    "## Question 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5bd37-9651-4fb2-8cd0-dc4d175dab14",
   "metadata": {},
   "source": [
    "```\n",
    "Sarah is developing a Python script for data analysis and visualization. She wants to ensure that her script is easy to maintain and understand by other team members. What is a recommended best practice for improving script maintainability?\n",
    "\n",
    "a) Using vague variable names to encourage code exploration.\n",
    "b) Writing functions with long and convoluted logic to minimize the number of functions.\n",
    "c) Dividing the script into smaller functions with clear names and specific responsibilities.\n",
    "d) Avoiding names comments in the code to keep it concise.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec101a-6eca-4f4a-808f-fb77e17c0682",
   "metadata": {},
   "source": [
    "## Solution 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077def5d-975b-45b7-83b3-ca2375ead46c",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3974f-3fb1-4c15-a699-ee071c6df934",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eefc5f7-a978-4b4c-b458-b734fdf5237a",
   "metadata": {},
   "source": [
    "## Question 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb51e6-b92e-4cb1-9a08-4fc94ff27ede",
   "metadata": {},
   "source": [
    "```\n",
    "You are debugging a Python script that is intended to calculate the average of a list of numbers. However, the script is returning incorrect results. What debugging technique should you use to identify the calculation error?\n",
    "\n",
    "a) Add more test cases to cover a wider range of scenarios.\n",
    "b) Print the list of numbers before and after the calculation.\n",
    "c) Rewrite the calculation logic using a different algorithm.\n",
    "d) Step through the script using a debugger and inspect variable values.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c1520-fc05-423b-aff3-7ca0c25495e6",
   "metadata": {},
   "source": [
    "## Solution 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee8758-3e99-44f2-aec7-b1d6e2910e73",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0642c-ae32-4d19-8ad5-d7049198ff0c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d696862-ee25-49a9-b801-7b62de60664f",
   "metadata": {},
   "source": [
    "## Question 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b8345-40e2-4576-9976-6cc4c3dc2c4a",
   "metadata": {},
   "source": [
    "You are working with a small dataset and want to assess your model's performance. Your colleague recommends using k-fold cross-validation. However, you are concerned about the reliability of the evaluation. What cross-validation technique would be most appropriate for your small dataset?\n",
    "\n",
    "a) Shuffle-Split Cross-Validation\n",
    "\n",
    "b) Time Series Cross-Validation\n",
    "\n",
    "c) Leave-One-Out Cross-Validation\n",
    "\n",
    "d) Stratified k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837012a-e95c-4f37-82c7-ad2add1afd1f",
   "metadata": {},
   "source": [
    "## Solution 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb8e75-39fb-4867-a284-73d2564759ee",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d1db6-a3cb-4781-952d-a9df2af8a493",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1dc27a-13d9-450c-b74e-790368a42914",
   "metadata": {},
   "source": [
    "## Question 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bc41f-94ac-4bdd-a8eb-57cabd6cb83d",
   "metadata": {},
   "source": [
    "```\n",
    "You are tasked with optimizing a Python script that processes a large dataset. During testing, you notice that the script’s memory usage keeps increasing over time, leading to potential memory leaks. What debugging technique should you use to identify and fix the memory leak issue?\n",
    "\n",
    "a) Add print statements to track memory usage.\n",
    "b) Use a profiler to analyze memory usage patterns.\n",
    "c) Comments out sections of code to isolate the issue.\n",
    "d) Rewrite the script using a different programming paradigm.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf2644-67dd-4bbd-8ab0-0b6041765599",
   "metadata": {},
   "source": [
    "## Solution 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2d025-5b71-4cbb-982f-92cdb05effda",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01cb97-90d2-493a-bb9c-1ff106656648",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce02be-e7c1-4665-ab49-5fa8e6b2cac9",
   "metadata": {},
   "source": [
    "## Question 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c925b59-2d88-4bf4-81e5-363743afaed6",
   "metadata": {},
   "source": [
    "```\n",
    "Alex is tasked with optimizing a Python script for data processing. What coding practice should Alex prioritize to enhance the script’s maintainability?\n",
    "\n",
    "a) Using global variables extensively to simplify data sharing between functions.\n",
    "b) Creating functions with overly general names to accommodate multiple functionalities.\n",
    "c) Implementing meaningful variable names and organizing code into logical sections.\n",
    "d) Embedding documentation only in external files separate from the code.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d31211-0299-4442-b511-4a6139cb88dc",
   "metadata": {},
   "source": [
    "## Solution 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38527df3-111c-4662-9025-878297929a5a",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbac03-770f-4667-addd-706eb6b47379",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcd3da-69cb-401b-b6a9-059afcb824e8",
   "metadata": {},
   "source": [
    "## Question 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f1848-febd-4d37-9983-e56cbba84200",
   "metadata": {},
   "source": [
    "```\n",
    "You are working with a dictionary in Python that stores information about students and their scores. Which code snippet correctly accesses the score of the student named “John” from the dictionary?\n",
    "\n",
    "a) scores['John']\n",
    "b) scores.get('John')\n",
    "c) scores['scores']['John']\n",
    "d) scores.get('John', 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a79e1-bbba-42d8-b662-3e3198b9488d",
   "metadata": {},
   "source": [
    "## Solution 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10f858-b758-4f58-8bd8-3ee2919b84e5",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8504c-21c4-486e-add9-0fa1d2ec496f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ffc90-19e3-4c77-8505-30cf86529368",
   "metadata": {},
   "source": [
    "## Question 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35f504-ca28-4172-a1ac-87ce5909a21d",
   "metadata": {},
   "source": [
    "```\n",
    "You are debugging a Python script that is supposed to extract specific information from a JSON file but encounters errors during execution. Which approach is most effective for identifying and fixing these errors?\n",
    "\n",
    "a) Rewrite the entire script using a different programming paradigm for better error handling.\n",
    "b) Utilize try-except blocks to catch and handle specific exceptions that occur during script execution.\n",
    "c) Increase the script's memory allocation to prevent runtime errors related to memory exhaustion.\n",
    "d) Ignore the errors and proceed with running the script to see if it resolves itself.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df888e-7f7a-4df8-867c-af2a973c8013",
   "metadata": {},
   "source": [
    "## Solution 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb2730-6dc4-4b45-a133-31189a9e5cab",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a83f-86ff-4569-b04b-61eace81c4c5",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88c062-0d81-4431-8f79-dc6734718286",
   "metadata": {},
   "source": [
    "## Question 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b38682-e7ce-47a2-b7f7-6e044b8633db",
   "metadata": {},
   "source": [
    "```\n",
    "A data analyst is working with a dataset containing numerical values in the ‘age’ column. They need to ensure that all age entries are within the range of 18 to 65 years. Which data validation technique should the analyst use for this task?\n",
    "\n",
    "a) Regular expression matching to validate the age format.\n",
    "b) Applying a lambda function to check for values outside the range.\n",
    "c) Using the pd.cut() function to categorize ages into bins.\n",
    "d) Using the pd.to_numeric() function with errors set to 'coerce' and then checking for NaN values.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67381e16-8255-4ef5-b1f5-69c29d6ded50",
   "metadata": {},
   "source": [
    "## Solution 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70992073-ab10-45dd-83a8-ece60d5f4324",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b251c39-21ba-4140-823e-dc9b2e46b41e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e56b05-ade3-4f05-a439-2aca77c52475",
   "metadata": {},
   "source": [
    "## Question 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe43b0-7364-4b1e-817d-ff7e452587b3",
   "metadata": {},
   "source": [
    "You conducted a correlation analysis between two variables and obtained a correlation coefficient of -0.75. What does this correlation coefficient value indicate about the relationship between the variables?\n",
    "\n",
    "a) There is a strong positive correlation between the variables.\n",
    "\n",
    "b) There is a moderate positive correlation between the variables.\n",
    "\n",
    "c) There is a strong negative correlation between the variables.\n",
    "\n",
    "d) There is no correlation between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfd08a-5f3a-48cc-bfb2-29f34eefe7e3",
   "metadata": {},
   "source": [
    "## Solution 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70baab-1d85-40d7-9f92-672f9f15d25d",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc778be7-505d-4942-b27d-dbffe69c6d83",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79468bf5-e38e-46e1-a51c-88ab86fd9664",
   "metadata": {},
   "source": [
    "## Question 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02943052-5d6b-4f1e-bf3f-88944fad3a7e",
   "metadata": {},
   "source": [
    "You are tasked with validating a dataset containing ages of customers. Which data validation technique would be most appropriate to ensure the reliability and accuracy of the age data?\n",
    "\n",
    "a) Completeness validation\n",
    "\n",
    "b) Format validation.\n",
    "\n",
    "c) Range validation.\n",
    "\n",
    "d) Consistency validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9c4ff-a977-4a6f-85e5-ae6e03060bd5",
   "metadata": {},
   "source": [
    "## Solution 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3954a-d730-4533-8f43-8985c3c7b8fb",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d94c67-bf29-452c-ac50-26a7062b61ef",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d54e5b-b50e-4067-befe-bc1fd60dee9a",
   "metadata": {},
   "source": [
    "## Question 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7572b0-477d-47a6-8059-501b15328753",
   "metadata": {},
   "source": [
    "You have employed 5-Fold Cross-Validation on a binary classification problem and received the following accuracy scores for each fold: [0.8, 0.85, 0.9, 0.7, 0.6]. What should be your next course of action?\n",
    "\n",
    "a) Consider the model to be robust as the accuracy is above 50% for all folds.\n",
    "\n",
    "b) Increase the number of folds to 10 for a more precise evaluation.\n",
    "\n",
    "c) Investigate the cause of the variability in the accuracy scores across folds.\n",
    "\n",
    "d) Pick the best model from the third fold, as it has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8fc72b-ae26-4e78-8020-ad85b1373b49",
   "metadata": {},
   "source": [
    "## Solution 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ee66a-a0bc-4a25-b4c6-44f771de2d6b",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1466ea-9027-47fe-adf5-fd715d477680",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e17c3f-b431-439c-bc0e-258c01d687f0",
   "metadata": {},
   "source": [
    "## Question 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be993cea-00a2-42bb-aec3-0e67e1108df7",
   "metadata": {},
   "source": [
    "Suppose you have a DataFrame df with columns Name, Age, Gender, and Salary. Which of the following code snippets will filter the DataFrame to include only rows where Age is more than 25 and Salary is less than 50000, and also sort the resulting DataFrame by Name?\n",
    "\n",
    "a) ```df.filter('Age' > 25 & 'Salary' < 50000).sort_values(by='Name')```\n",
    "\n",
    "b) ```df[(df['Age'] > 25) & (df['Salary'] < 50000)].sort_values('Name')```\n",
    "\n",
    "c) ```df.sort_values('Name').where(df['Age'] > 25 & df['Salary'] < 50000)```\n",
    "\n",
    "d) ```df.query('Age > 25 and Salary < 50000').sort('Name')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f867f0e-2f96-4e8a-9b05-fde4117be2bf",
   "metadata": {},
   "source": [
    "## Solution 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f15045-f6db-45ee-bccf-3c901b42c139",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45bb551-fc26-443a-a3a7-7082bb9742d8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533e791-7f4c-4b19-ba75-c8bd48374478",
   "metadata": {},
   "source": [
    "## Question 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e453360-07aa-4877-94e0-fe5aa3bc68dd",
   "metadata": {},
   "source": [
    "Given the Python code snippet below, which utilizes Matplotlib to generate a plot, what type of chart will be produced?\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "a = [2, 4, 6, 8, 10]\n",
    "b = [1, 3, 5, 7, 9]\n",
    " \n",
    "plt.plot(a, b, color='green', linestyle='solid', marker='s',\n",
    "         markerfacecolor='yellow', mec='blue', linewidth=1.5, alpha=0.9,\n",
    "         label='Custom Plot')\n",
    "plt.xlabel('A Axis')\n",
    "plt.ylabel('B Axis')\n",
    "plt.title('Example Plot')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "a) A scatter plot with square markers, green lines, and yellow marker faces.\n",
    "\n",
    "b) A bar chart with green bars and yellow edges.\n",
    "\n",
    "c) A line plot with square markers, green lines and yellow marker faces.\n",
    "\n",
    "d) A pie chart with segment labled \"Custom Plot\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec84e1-6c65-4cea-a959-3d06b2d846f9",
   "metadata": {},
   "source": [
    "## Solution 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b24958-8e85-4eca-84bc-55adf799dfcd",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fbb89-4252-423d-8af5-a7473677e2fd",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcbe18-4fde-413d-8769-d169992f2e07",
   "metadata": {},
   "source": [
    "## Question 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367e013-0d55-4076-9c4f-0ba668ca403d",
   "metadata": {},
   "source": [
    "You have the following DataFrame containing sales data:\n",
    "\n",
    "\n",
    "```\n",
    "df = pd.DataFrame({\n",
    "    'Month': ['Jan', 'Jan', 'Feb', 'Feb', 'Mar', 'Mar'],\n",
    "    'Product': ['A', 'B', 'A', 'A', 'B', 'C'],\n",
    "    'Sales': [100, 150, 200, 50, 300, 400]\n",
    "})\n",
    "```\n",
    "\n",
    "You want to find the total sales for each month. Which code snippet will achieve this?\n",
    "\n",
    "a) ```df.groupby('Month').sum()```\n",
    "\n",
    "b) ```df.groupby('Product').sum('Sales')```\n",
    "\n",
    "c) ```df['Month'].agg({'Sales': 'sum'})```\n",
    "\n",
    "d) ```df.groupby('Month').agg({'Sales': 'sum'})```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af8b63-b853-40a8-af0d-deae0570cb6a",
   "metadata": {},
   "source": [
    "## Solution 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86bc3d-badf-4aec-b558-c0713e8c836d",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02624d-f990-4706-aebf-8765f4830ea7",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba979f97-7ad0-4a3f-b316-bb730ea07317",
   "metadata": {},
   "source": [
    "## Question 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474a0a4-2612-458b-84bc-f1acb8b4d779",
   "metadata": {},
   "source": [
    "You have a DataFrame df with columns 'Quarter', 'Revenue', and 'Expenses'. You are tasked with calculating the quarterly profit margin as (Revenue - Expenses) / Revenue. Which of the following will correctly add a 'Profit Margin' column with these calculated values?\n",
    "\n",
    "a) ```df['Profit Margin'] = (df['Revenue'] - df['Expenses']) / df['Revenue']```\n",
    "\n",
    "b) ```df['Profit Margin'] = df['Revenue'] - df['Expenses'] / df['Revenue']```\n",
    "\n",
    "c) ```df['Profit Margin'] = df['Revenue'] / (df['Revenue'] - df['Expenses']) ```\n",
    "\n",
    "d) ```df['Profit Margin'] = df.apply(lambda row: (row['Revenue'] - row['Expenses']) / row['Revenue'], axis=1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a34b6d-110d-4bcd-8d48-ee07f4d0c0d5",
   "metadata": {},
   "source": [
    "## Solution 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3706f-0aac-411f-9b63-6f166cea35f1",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefeb74f-7e78-4420-9896-a1f7a05a367d",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae643893-071f-47e2-b9c8-a878b5e81c77",
   "metadata": {},
   "source": [
    "## Question 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e36a7-0051-4f88-8213-1faa1ac048e5",
   "metadata": {},
   "source": [
    "Your dataset contains monthly sales figures for different products over the past year. You want to visualize the sales trends for each product over time. Which type of visualization is most suitable for this task?\n",
    "\n",
    "a) Line Plot\n",
    "\n",
    "b) Box Plot\n",
    "\n",
    "c) Pie Chart\n",
    "\n",
    "d) Scatter Plot\n",
    "\n",
    "e) Bar chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378415ee-0b52-4559-9273-ad8a22e45c43",
   "metadata": {},
   "source": [
    "## Solution 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df656073-dd4a-43f8-8e65-b8e4a92a6942",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7694306-8775-4aa3-b1f2-c273d7666bef",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952f9ef-fd94-4770-a4ef-e6a24c43cf4e",
   "metadata": {},
   "source": [
    "## Question 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2676ae-8393-450c-adf8-05e203f75f83",
   "metadata": {},
   "source": [
    "You are analyzing a dataset containing daily temperature readings from multiple cities over a year. You want to visualize this data to compare the temperature trends across these cities. Which of the following visualization techniques would be most suitable for this purpose?\n",
    "\n",
    "a) Barc Chart\n",
    "\n",
    "b) Multiple Line Graphs on the same Plot\n",
    "\n",
    "c) Scatter Plot\n",
    "\n",
    "d) Pie Chart\n",
    "\n",
    "e) Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d81007-e04d-406a-86af-c8f853633784",
   "metadata": {},
   "source": [
    "## Solution 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc2fcb-9e02-4b59-8372-faca0a290f15",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bd95a-6775-4a40-b6b1-79dd9d5cae5e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85fe0c-6f3f-44df-b4de-d7b99c15ff10",
   "metadata": {},
   "source": [
    "## Question 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5abddb-5ca5-4a5f-ae89-2000a79089b3",
   "metadata": {},
   "source": [
    "In your climate study, you're examining the relationship between average yearly sunshine hours and average annual temperature in different countries. Additionally, you want to emphasize countries with the highest and lowest average yearly sunshine hours. What type of data visualization would be most suitable for this analysis?\n",
    "\n",
    "a) Histogram\n",
    "\n",
    "b) Scatter Plot with color Coding\n",
    "\n",
    "c) Bubble Chart with Size Variation\n",
    "\n",
    "d) Stacked Area Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387528cb-bbe7-4a2f-a94c-e60d86cd3b83",
   "metadata": {},
   "source": [
    "## Solution 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282eaf4-0e78-4d09-866c-d089561c8794",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15398e3e-d066-4afb-82ee-161a09ecc116",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6589a15-cdbe-49ac-9573-b0e4731f395d",
   "metadata": {},
   "source": [
    "## Question 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd8f20-6460-4763-967f-a1857180d86c",
   "metadata": {},
   "source": [
    "In the context of an ETL (Extract, Transform, Load) process, what is the primary purpose of the 'Extract' phase?\n",
    "\n",
    "a) Loading data into a data warehouse or database\n",
    "\n",
    "b) Retrieving and reading data from multiple heterogeneous data sources\n",
    "\n",
    "c) Creating visualizations and reports for end-users.\n",
    "\n",
    "d) Performing data cleaning and preparation for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf7786-cb44-45d1-b013-b162b4349161",
   "metadata": {},
   "source": [
    "## Solution 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd7df1-4185-4f85-a5b7-a9a19980415f",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4e7d2-5041-4d94-84a6-40886e555627",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f19524-e1a9-46fc-8807-d85bf67988fe",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
