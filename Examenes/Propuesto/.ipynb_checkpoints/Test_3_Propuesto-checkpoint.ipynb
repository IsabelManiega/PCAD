{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6076dd72-eeb2-441c-8e5b-dc41534716ad",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08190a05-f597-4050-8c04-2490e94d5365",
   "metadata": {},
   "source": [
    "# Test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a29adb-2ab4-4fe3-819b-ac32fcba9a8d",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be63f-e320-47da-9425-fc597e89a82f",
   "metadata": {},
   "source": [
    "```\n",
    "For a project analyzing traffic patterns in a city, what is the most effective method of data collection to obtain real-time traffic flow information?\n",
    "\n",
    "a) Administering questionnaires to drivers.\n",
    "b) Using traffic cameras and sensors to monitor roads.\n",
    "c) Conducting interviews with city planners.\n",
    "d) Reviewing historical traffic data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfb34a-1a1c-4e74-98fe-625f05ea6b1f",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ee3e2-6484-4a02-a5d9-850ef56ffa7c",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b184278-da3b-4951-8a02-f2035f1bb2aa",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099602d-35ff-42cc-b899-f13b1dadbac5",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c0c0e-3958-4d15-a23b-a03c3a35d545",
   "metadata": {},
   "source": [
    "```\n",
    "You have to retrieve data from a database table named employees. The table contains columns employee_id, first_name, last_name, department, and salary. Your goal is to retrieve only the first_name and salary of all employees where the department is 'HR'. Which SQL query most likely accomplishes this task?\n",
    "\n",
    "a) SELECT first_name, salary FROM employees WHERE department NOT 'HR';\n",
    "b) SELECT first_name, salary FROM employees WHERE department = 'HR';\n",
    "c) SELECT first_name, last_name, salary FROM employees WHERE department IS 'HR';\n",
    "d) SELECT first_name, salary FROM employees WHERE department = 'HR' AND salary;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af231fc-6d04-4ab3-9b5f-86dea6f6fd50",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40636e-490c-4245-9c96-6c4e907ba165",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e478e9e-00db-41c5-906b-5eb485f52a53",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19445330-c76a-4cc7-b73c-cac86b07bb99",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547fd4e-65a8-4750-9833-54fa085fda4a",
   "metadata": {},
   "source": [
    "```\n",
    "You are validating data from various sources, including text files, CSV files, audio recordings, and social media APIs. Which aspect of data validation is most critical for ensuring the reliability and accuracy of this heterogeneous data?\n",
    "\n",
    "a) Checking data type consistency.\n",
    "b) Verifying data completeness.\n",
    "c) Ensuring data integrity.\n",
    "d) Performing format validation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283243f4-b6db-47f2-92dd-b56bbc326b7d",
   "metadata": {},
   "source": [
    "## Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f0e72-bf02-4fec-9240-97409df09e1b",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad867626-5a19-4771-a627-d53941496831",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ad67f-f450-45af-8ade-211d67a4dadc",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6af70-058c-4b00-b3f3-bc8ae24e871b",
   "metadata": {},
   "source": [
    "```\n",
    "Sophia is responsible for validating data from text files, Excel spreadsheets, audio clips, and social media feeds. What should be Sophia’s primary concern in ensuring the reliability and accuracy of this data?\n",
    "\n",
    "a) Ensuring data consistency\n",
    "b) Performing data format validation\n",
    "c) Verifying data completeness.\n",
    "d) Conducting data integrity checks.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5909a-b1ce-4d9b-9d72-dc1983e03eb6",
   "metadata": {},
   "source": [
    "## Solution 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7972849-130c-4e45-a9cc-a58b7011c728",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9b33e-fa10-4910-ac22-b058d5601c82",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca3475-c0cc-4c29-9058-9768213ce09a",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a95c7-8132-4e31-a103-fbe190631f43",
   "metadata": {},
   "source": [
    "You are given a DataFrame df with columns 'Name', 'Age', and 'Occupation'. You want to filter the rows where 'Age' is greater than 30 and 'Occupation' is 'Engineer'. Which of the following code snippets will correctly achieve this?\n",
    "\n",
    "a) `df[(df['Age'] > 30) and (df['Occupation'] == 'Engineer')]`\n",
    "\n",
    "b) `df[df['Age'] > 30].df['Occupation'] == 'Engineer']`\n",
    "\n",
    "c) `df[(df['Age'] > 30) & (df['Occupation'] == 'Engineer')]`\n",
    "\n",
    "d) `df[(df['Age'] > 30) and (df['Occupation'] == Engineer)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d12c1-fd60-4587-86f8-8eaa9b5d969a",
   "metadata": {},
   "source": [
    "## Solution 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c84e3-4550-4be3-a019-78c817e85cc5",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79438efa-61e5-4dfb-adb0-8bed7e48a55b",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6273ab0-b22a-487d-b0e4-ee14d8fa35f3",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5586e76-3e9b-4dce-9bca-eaa0deac99b7",
   "metadata": {},
   "source": [
    "```\n",
    "In a dataset containing audio file references for a voice recognition system, how should a data analyst validate that each audio file is in the correct format and of sufficient quality for analysis?\n",
    "\n",
    "a) Listen to a sample of the audio files manually.\n",
    "b) Verify the file extnsion matches the required audio format.\n",
    "c) Check the metadata for each audio file to confirm format and quality specifications.\n",
    "d) Transcribe the audi files using voice recognition software to ensure clarity.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c073be-0b7e-4079-9214-ee2302e8fc8b",
   "metadata": {},
   "source": [
    "## Solution 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38deab75-f216-43a7-baf7-18141a8bfc58",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009f39f-6a4d-4b8c-a044-1f229bcf6869",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac6605-0cae-4c15-be7c-d7fd89c69736",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e5aa9-705e-492e-abc3-67ed09b29b02",
   "metadata": {},
   "source": [
    "```\n",
    "You are analyzing a dataset for predicting customer preferences in an e-commerce platform. The dataset includes features such as product category, price, customer ratings, and purchase history. What is a recommended step for preparing this dataset for modeling?\n",
    "\n",
    "a) Convert the \"Product Category\" feature into numerical values using label encoding.\n",
    "b) Standarize the \"Price\" feature using Min-Max scaling to ensure consistent scales across features.\n",
    "c) Drop the \"Purchase History\" feature as it is not relevant for predicting customer preferences.\n",
    "d) Impute missing values in the \"Customer Ratings\" feature with the mean rating value.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47abb98-26e9-4e2a-b16d-fbe173740baf",
   "metadata": {},
   "source": [
    "## Solution 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271b89b-0f61-4cf6-b016-cb93610fa44f",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702e2e3-6d4a-47a5-9b61-a6a9cb2d0b66",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5f201-3390-4f0a-8ce2-8b3918339938",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3e627-2c8b-432e-94a8-b41d260c84e7",
   "metadata": {},
   "source": [
    "```\n",
    "You are working on a dataset for predicting customer churn in a telecommunications company. The dataset includes columns for customer ID, age, monthly charges, and whether the customer churned or not. What is a recommended step for preparing this dataset for modeling using Python?\n",
    "\n",
    "a) Convert the \"Churn\" column into numerical values using label encoding.\n",
    "b) Impute missing values in the \"Monthly Charges\" column with the median value.\n",
    "c) Scale the \"Age\" column using Min-Max scaling to ensure uniformity in the feature scales.\n",
    "d) Remove outliers from the \"Monthly Charges\" column to improve model preformance.\n",
    "\n",
    "*customer churn: perdida de clientes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05988f2c-7076-4c40-9f3f-1b997ee3e2fb",
   "metadata": {},
   "source": [
    "## Solution 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36f587-5b60-471e-986f-3552c15d8607",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78efa344-4df8-455c-b226-d942aa654868",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57dfe9-3730-4a96-947f-4af1410cd670",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d93a9-4d5b-409e-804f-8ad3bde979be",
   "metadata": {},
   "source": [
    "```\n",
    "You are tasked with validating data collected from a survey, including text responses, numeric ratings, audio feedback, and video testimonials. What should be the primary focus of your data validation procedures to ensure the reliability and accuracy of this diverse dataset?\n",
    "\n",
    "a) Ensuring data type consistency.\n",
    "b) Validating data format.\n",
    "c) Checking data range.\n",
    "d) Cross-referencing data with external sources.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477c97d-549d-4ca4-bfe0-7b7ba55634b1",
   "metadata": {},
   "source": [
    "## Solution 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f906ed0b-8f01-4bf4-a061-3aba0581bdb3",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e887c8-8b80-4dc4-8537-a53d1da6b2df",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8e7da-799e-45a9-b5ab-dfa438a5552b",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81763b-fc1a-4905-83fb-dea5f090b27d",
   "metadata": {},
   "source": [
    "```\n",
    "In a clinical trial dataset, some participants have missing values for their blood pressure readings. What is the most appropriate method for handling these missing values to ensure a comprehensive analysis?\n",
    "\n",
    "a) Assign the highest recorded blood pressure value to the missing entries.\n",
    "b) Use interpolation methods to estimate the missing values based on nearby data points.\n",
    "c) Exclude all participants with missing blood presure reading from the study.\n",
    "d) Categorize the missing values as a separate group in the analysis.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083f9ef-f6d2-48d7-95f9-88aecd58f5af",
   "metadata": {},
   "source": [
    "## Solution 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d276b11-6cd9-4a65-a0fa-a92bacc923ad",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b219078-094a-4735-9f91-23ff50fe4661",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe33b7-3f4e-4cb6-b5d4-b01d5858cb1c",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfe09b-7177-49bb-9b81-950a4896639b",
   "metadata": {},
   "source": [
    "```\n",
    "om is analyzing a dataset of video file paths for a digital media project. He needs to ensure that each path leads to a valid video file. Which method should Tom use to validate the video files effectively?\n",
    "\n",
    "a) Check that each file path ends with a video file extension (eg., mp4, avi)\n",
    "b) Play each video file to check its validity manually.\n",
    "c) Run a script that verifies each file path exists and points to a file the correct format.\n",
    "d) Look at the file sizes to ensure they are within a reasonable range for video files.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a9f104-b702-4416-b431-e4ef3830fab1",
   "metadata": {},
   "source": [
    "## Solution 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd6923-834c-487e-bcf9-d6226d49def7",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe2404-e85e-4ead-8239-03b5c5cfb273",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715fdfc-8ca0-4dd2-915b-81fad8fee2ba",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ee237-9064-4dc6-b047-cf32aa873bae",
   "metadata": {},
   "source": [
    "```\n",
    "Julia is processing a dataset for a social media analysis project and needs to verify that all usernames mentioned in the data are valid and active on the platform. What should Julia do to validate this information efficiently?\n",
    "\n",
    "a) Manually search for each username on the social media platform.\n",
    "b) Use the social media patform's API to check the status of each username.\n",
    "c) Validate the format of the usernames using regular expressions.\n",
    "d) Confirm the number of followers for each username to ensure activity.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e8182-4896-48bc-84ff-191f59e53a33",
   "metadata": {},
   "source": [
    "## Solution 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8f6c2-c72a-4dfc-95f3-d989c00c6ba2",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57624365-ce10-47fe-8140-532c746dfd2f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379b835-22b4-4bcf-8141-542a8c99ac43",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83965f-7384-4279-9bed-28b81ca4cd46",
   "metadata": {},
   "source": [
    "```\n",
    "Jason needs to collect historical weather data to analyze climate trends over the past 50 years for a geographic region. Which source should he use to obtain the most comprehensive and reliable data?\n",
    "\n",
    "a) Local newspaper archives.\n",
    "b) An online climate database accessed via API.\n",
    "c) Personal interviews with long-time residents.\n",
    "d) Social media posts related to weather events.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91448030-bf92-4523-94e9-bcdd25748617",
   "metadata": {},
   "source": [
    "## Solution 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc93e0-ff87-4a5d-a768-e75ec20ef269",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016e372-7fa8-4020-bb96-8b75622756f8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbaab78-024a-4739-9bb3-e3e92a580d3d",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b72dd-d763-4d8b-a1be-94b69cf09621",
   "metadata": {},
   "source": [
    "```\n",
    "You are creating a dashboard to analyze customer feedback data for a service-oriented company. Which dashboard-building tool would be most suitable for integrating data from multiple sources, such as surveys, social media platforms, and customer support tickets?\n",
    "\n",
    "a) Microsoft Excel.\n",
    "b) Google Data Studio.\n",
    "c) Tableau.\n",
    "d) Power BI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec1e4d-268c-4e1d-a624-fbb0ba5b7a8b",
   "metadata": {},
   "source": [
    "## Solution 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56d246-9d73-47e4-a410-dce6df30db1e",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b642ac-f89b-4672-bd1e-8929e0762aaa",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07566e27-dbad-4989-9b2a-215435d2e095",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5f71d-bcc3-4b11-bebd-117ebf5174d3",
   "metadata": {},
   "source": [
    "You are working as a data analyst for a retail company and have been tasked with creating a dashboard to visualize sales performance for different product categories over time. The dataset includes columns for “Date,” “Product Category,” and “Sales Amount.” Which type of chart or visualization would be most suitable for this task?\n",
    "\n",
    "a) Line chart showing sales amount over time with different lines for each product category.\n",
    "\n",
    "b) Scatter plot showing sales amount against date for each product category.\n",
    "\n",
    "c) Bar chart showing total sales amount for each product category on a specific date.\n",
    "\n",
    "d) Pie chart showing the percentage contribution of each product category to total sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4727ce0-0fbe-4da7-9c41-8c88832d27cd",
   "metadata": {},
   "source": [
    "## Solution 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a794c7-f38d-4299-af92-03e9094afb82",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277bc4fa-febe-41a1-b91b-d5223d450ff1",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab1295-a706-4774-b2a5-71fd5da167b2",
   "metadata": {},
   "source": [
    "## Question 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258e9da-6037-42c0-ac1a-b4425559211a",
   "metadata": {},
   "source": [
    "```\n",
    "You need to create a dashboard to track social media metrics such as engagement rate, follower growth, and content performance for a digital marketing campaign. Which dashboard-building tool would be most suitable for visualizing social media analytics data?\n",
    "\n",
    "a) Tableua\n",
    "b) Google Data Studio\n",
    "c) Microsoft Excel\n",
    "d) Power BI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fbc2b-98f4-4e41-86a4-b43b56980227",
   "metadata": {},
   "source": [
    "## Solution 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b514f4a-8cdf-4e9e-af1f-abe5d016b153",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2670f4-72dc-4197-832f-dd95710cafaf",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ec0f8-4b00-4943-8957-13d7e16f14a0",
   "metadata": {},
   "source": [
    "## Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b385c-dfaf-43cb-8f1d-bbd47a399344",
   "metadata": {},
   "source": [
    "```\n",
    "Emily is working on a dataset that contains outliers in one of the numerical columns. What preprocessing technique should Emily apply to handle outliers before modeling?\n",
    "\n",
    "a) Remove the outliers.\n",
    "b) Replace outliers with the median of the column\n",
    "c) Use z-score normalization to scale the column.\n",
    "d) Apply clustering to identify and adjust outliers.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a800b9e-eab0-4101-93b2-4d9d9c06c50f",
   "metadata": {},
   "source": [
    "## Solution 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621028e-26ba-409d-b3a0-c0fdbb92ddd1",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f291ae-62f3-4d5a-8b9a-de9c55dff2d8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7092f6c-cd2f-41b1-99d6-cc25ead32a50",
   "metadata": {},
   "source": [
    "## Question 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1226288-2625-4ce0-b6a8-354db9c45dd6",
   "metadata": {},
   "source": [
    "Consider the following Python code snippet:\n",
    "```\n",
    "fruit = \"banana\"\n",
    "numbers1 = (8, 3, 9, 2)\n",
    "numbers2 = (5, 7, 6, 1)\n",
    "combined_numbers = numbers1 + numbers2\n",
    "unique_set = set([ord(fruit[2]), combined_numbers[7]])\n",
    " \n",
    "print(\"Third Character:\", fruit[2])\n",
    "print(\"Eighth Number:\", combined_numbers[7])\n",
    "print(\"Unique Set:\", unique_set)\n",
    "```\n",
    "Knowing that the ASCII value for the character 'n' is 110, what will be the output of this code?\n",
    "\n",
    "a)\n",
    "```\n",
    "Third Character: n\n",
    "Eighth Number: 1\n",
    "Unique Set: {1, 110}\n",
    "```\n",
    "\n",
    "b)\n",
    "```\n",
    "Third Character: n\n",
    "Eighth Number: 1\n",
    "Unique Set: {n, 49}\n",
    "```\n",
    "\n",
    "c)\n",
    "```\n",
    "Third Character: n\n",
    "Eighth Number: 1\n",
    "Unique Set: {n, 1}\n",
    "```\n",
    "\n",
    "d)\n",
    "```\n",
    "Third Character: n\n",
    "Eighth Number: 1\n",
    "Unique Set: {110, 49}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03716e-d828-45ad-ae5d-d739fe6b2044",
   "metadata": {},
   "source": [
    "## Solution 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f181d-1551-4d9f-a739-c2a86141d034",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59aab5a-25c0-4b99-b97c-caa68a8976c3",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736019e-6c43-4d2c-af33-b3ea1a6930ba",
   "metadata": {},
   "source": [
    "## Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11765449-968d-4ec2-8c7a-f821e327d5f7",
   "metadata": {},
   "source": [
    " To streamline library management, a librarian aims to highlight books with exceptional borrowing rates. The librarian has a dataset containing monthly borrowing counts for various books and decides to use Python to isolate books with counts exceeding a specific threshold, indicating high demand.\n",
    "```\n",
    "borrowing_counts = [5, 15, 8, 20, 12, 25]\n",
    "popular_books = [count for count in borrowing_counts if count > 10]\n",
    " \n",
    "print(popular_books)\n",
    "```\n",
    "What is the primary objective of this Python code in the context of data management principles?\n",
    "\n",
    "a) Grouping borrowing counts into categories to classify books by their popularity.\n",
    "\n",
    "b) Identifying the average borrowing count to find the mean demand for books.\n",
    "\n",
    "c) Filtering the dataset to only include books that have borrowing counts above a certain threshold.\n",
    "\n",
    "d) Creating a new list that inlcudes both the book titles and their borrowing counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e1acb-dbd9-4575-b4bf-89b15e2be8e0",
   "metadata": {},
   "source": [
    "## Solution 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff020192-7fc6-44e2-9c97-b3712b05ac4f",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88f8dc-d983-4ae7-9817-4591e68d06c8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207eee0-1579-4acd-af28-dbf9adcb0967",
   "metadata": {},
   "source": [
    "## Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb59686-8461-407d-aee3-61f2964b21d8",
   "metadata": {},
   "source": [
    "You have a list of numbers ```[10, 20, 30, 40, 50]``` in Python. You want to create a new list containing the squares of each number in the original list. Which of the following code snippets accomplishes this task?\n",
    "\n",
    "a ) ```[num ** 2 for num in [10, 20, 30, 40, 50]] ```\n",
    "\n",
    "b) ```[num * num for num in [10, 20, 30, 40, 50]] ```\n",
    "\n",
    "c) ```[num ^ 2 for num in [10, 20, 30, 40, 50]] ```\n",
    "\n",
    "d) ```[pow(num, 2) for num in [10, 20, 30, 40, 50]] ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e18a7-c109-44bf-9fa5-81edc9c53cf6",
   "metadata": {},
   "source": [
    "## Solution 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd5692-ba67-42ac-bec4-70665323ec22",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ee091-76e9-421c-b785-3b4c530f2ba7",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea66ea-ddb8-494f-aa19-621ba896cb8e",
   "metadata": {},
   "source": [
    "## Question 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8ca86-2d87-4078-b6e2-54365eafed57",
   "metadata": {},
   "source": [
    "```\n",
    "In a dataset containing details of online transactions, Jessica finds that the ‘transaction_date’ column has some entries with future dates. How should Jessica classify these entries during data cleaning?\n",
    "\n",
    "a) As accurate data, since future transactions can be pre-recorded.\n",
    "b) As complete data, because the date column is fully populated.\n",
    "c) As irrelevant data, since they do not affect the analysis.\n",
    "d) As erroneous data, because transaction dates chould not be in the future.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975e4e9-a857-4754-aa1d-77e36cf97ff1",
   "metadata": {},
   "source": [
    "## Solution 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6eb092-81a8-423a-a4a4-3ade405ea98d",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdc888-6747-4dc1-ab8c-05bb43497567",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34333e-87c2-40ef-99f9-bf357d7a92aa",
   "metadata": {},
   "source": [
    "## Question 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5266b00-4b56-42b8-8e0c-a9fc74055bbc",
   "metadata": {},
   "source": [
    "You are given a Python script that is supposed to calculate the average sales amount from a CSV file named “sales_data.csv” and print the result. However, when you run the script, it throws an error. Which approach is most appropriate for debugging this issue?\n",
    "\n",
    "a) Use print statements to trace the execution flow and identify the error.\n",
    "\n",
    "b) Utilize a Python debugger such as pdb to step through the code and find the error.\n",
    "\n",
    "c) Rewrite the entire script from scratch to ensure error-free execution.\n",
    "\n",
    "d) Ignore the error and proceed with running the script to see if it resolves itsef."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11d309-76d3-434c-aada-07ff9af116db",
   "metadata": {},
   "source": [
    "## Solution 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4dcfa-0545-474a-8c7b-7bae6f6f3f65",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b252fc2-7195-47d3-9676-315c77a936db",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2a8be-0055-4363-96f0-5bf540316efa",
   "metadata": {},
   "source": [
    "## Question 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483a568-882a-4eb2-bc1b-e4a25e147dd3",
   "metadata": {},
   "source": [
    "You are working with a dictionary in Python that contains student names as keys and their corresponding scores as values. You want to create a new dictionary that includes only students who scored above 90. Which of the following code snippets accomplishes this task?\n",
    "\n",
    "a) ```{student:score for student, score in student_scores.items() if score > 90}```\n",
    "\n",
    "b) ```{student:score if score > 90 else None for student, score in student_scores.items()}```\n",
    "\n",
    "c) ```{student:score for student, score in student_scores.items() if student_scores[student] > 90}```\n",
    "\n",
    "d) ```{student:score if student_scores[student] > 90 else None for student, score in student_scores.items()}```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0456b-1a5a-4884-afc1-3539a44ff31c",
   "metadata": {},
   "source": [
    "## Solution 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c4df5-d7da-474e-ac64-bb5ddef3155b",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49773963-0cc0-4d04-97e1-7db9cf55be93",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf94ef3-34a1-4075-b5c6-ae039bba26d5",
   "metadata": {},
   "source": [
    "## Question 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df389072-09ac-4d0a-b628-a108c455c55a",
   "metadata": {},
   "source": [
    "You have a SQLite database named “employees.db” that contains a table named “employees” with columns “id,” “name,” “age,” and “salary.” You need to write a Python script to connect to this database, retrieve all employees who are older than 40 years old and have a salary greater than $50,000, and then print their names. Which of the following code snippets correctly accomplishes this task using the sqlite3 library?\n",
    "\n",
    "a)\n",
    "```\n",
    "import sqlite3\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"employees.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve employees based on criteria\n",
    "cursor.execute(\"SELECT name FROM employees WHERE age > 40 AND salary > 50000\")\n",
    "employees = cursor.fetchall()\n",
    "\n",
    "# Print names of employees\n",
    "for employee in employees:\n",
    "    print(employee[0])\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "```\n",
    "\n",
    "b)\n",
    "```\n",
    "import sqlite3\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"employees.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve employees based on criteria\n",
    "cursor.execute(\"SELECT name FROM employees WHERE age > 40 AND salary > 50000\")\n",
    "employees = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Print names of employees\n",
    "print(employees)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "```\n",
    "c)\n",
    "```\n",
    "import sqlite3\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"employees.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve employees based on criteria\n",
    "cursor.execute(\"SELECT * FROM employees WHERE age > 40 AND salary > 50000\")\n",
    "employees = cursor.fetchall()\n",
    "\n",
    "# Print names of employees\n",
    "for employee in employees:\n",
    "    print(employee[\"name\"])\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "```\n",
    "\n",
    "d)\n",
    "```\n",
    "import sqlite3\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"employees.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve employees based on criteria\n",
    "cursor.execute(\"SELECT * FROM employees WHERE age > 40 AND salary > 50000\")\n",
    "employees = [row[\"name\"] for row in cursor.fetchall()]\n",
    "\n",
    "# Print names of employees\n",
    "print(employees)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a5946-a803-4ec4-bd26-727608cd599b",
   "metadata": {},
   "source": [
    "## Solution 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096a8c6-6e1b-4ff6-956e-61c6747cf643",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcf5b1-eeb7-42c1-9f89-c8c5b5be8530",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b658c4f-8e09-4cee-bb52-76ddf9082aa9",
   "metadata": {},
   "source": [
    "## Question 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0bcfc-6eda-4104-8bbb-1b7839033c4b",
   "metadata": {},
   "source": [
    "You are working with a list in Python that contains both strings and integers. You want to create a new list that includes only the integers from the original list. Which of the following code snippets accomplishes this task?\n",
    "\n",
    "a) ```[item for item in original_list if isinstance(item, int)]```\n",
    "\n",
    "b) ```[item if type(item) == int else None for item in original_list]```\n",
    "\n",
    "c) ```[item for item in original_list if type(item) == int]```\n",
    "\n",
    "d) ```[item if isinstance(item, int) else None for item in original_list]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596555e-e8ac-4098-b76c-8a563448bba1",
   "metadata": {},
   "source": [
    "## Solution 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45df18-abe0-4342-bbe7-6350fa966238",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57aeadb-8aa6-4d70-8237-7a74ee26ba55",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b7c22-25fb-45b2-bb2d-88e188734c11",
   "metadata": {},
   "source": [
    "## Question 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70aebe-d110-4fb7-ae5a-9a74e157ce5a",
   "metadata": {},
   "source": [
    "Which data validation technique is most suitable for ensuring that numeric data falls within a specific range?\n",
    "\n",
    "a) Data type validation \n",
    "\n",
    "b) Range validation.\n",
    "\n",
    "c) Cross-reference validation\n",
    "\n",
    "d) Format validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243174b-d07e-451a-957c-3078bf9baa2a",
   "metadata": {},
   "source": [
    "## Solution 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31276816-6454-4f43-acf9-7604a8a0d2b1",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bf19a-cce5-4091-97c2-7f152fb81f7a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c27bb3-c4a8-400b-8873-d36af51bf81c",
   "metadata": {},
   "source": [
    "## Question 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6602a-dd3f-4bef-a67b-d3d944c69656",
   "metadata": {},
   "source": [
    "You are tasked with optimizing a Python script that processes a large dataset. During testing, you notice that the script’s memory usage keeps increasing over time, leading to potential memory leaks. What debugging technique should you use to identify and fix the memory leak issue?\n",
    "\n",
    "a) Add print statements to track memory usage.\n",
    "\n",
    "b) Use a profiler to analyze memory usage patterns.\n",
    "\n",
    "c) Comment out sections of code to isolate the issue.\n",
    "\n",
    "d) Rewrite the script using a diffetent programming paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cfadc-42c2-48df-b41f-21aa7f70e36b",
   "metadata": {},
   "source": [
    "## Solution 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee9763-4047-4b62-9bff-cbaa2896f358",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2046731-6b6b-4c04-812f-1ab9bbd02890",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6daf99e-ffe8-4cf0-a05d-390055a3f6d8",
   "metadata": {},
   "source": [
    "## Question 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dea42-dea4-4939-a59d-6fa980d40331",
   "metadata": {},
   "source": [
    "You are analyzing a dataset containing information about student scores, including their ID, subject, and score obtained. You need to calculate the average score for students who have scored above 80 in the ‘Mathematics’ subject. Which of the following Python code snippets accomplishes this task?\n",
    "\n",
    "a) ```average_score = sum(student['score'] for student in student_data if student['subject'] == 'Mathematics' and student['score'] > 80 /len(student_data))```\n",
    "\n",
    "b) ```average_score = sum(student['score'] for student in student_data if student['subject'] == 'Mathematics' and student['score'] > 80)```\n",
    "\n",
    "c)  ```average_score = sum(student['score'] for student in student_data if student['subject'] == 'Mathematics' and student['score'] < 80 /len(student_data))```\n",
    "\n",
    "d) ```average_score = sum(student['score'] for student in student_data if student['subject'] != 'Mathematics' and student['score'] > 80 /len(student_data))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f43f-1ef4-4285-bd53-ef8637ae7e13",
   "metadata": {},
   "source": [
    "## Solution 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954b1d4-841c-43bc-b4f2-bc8b032a34b2",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3b1f8-e2af-4895-8249-6e4e50996e22",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b3190-dc18-4e1d-9d6d-40498d7b9084",
   "metadata": {},
   "source": [
    "## Question 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2998c-0728-4f36-b622-ca761bfb615c",
   "metadata": {},
   "source": [
    "You are analyzing a dataset containing information about product sales, including the product ID, quantity sold, and price per unit. You need to calculate the total sales revenue for a specific product with ID ‘ABC123’. Which of the following Python code snippets accomplishes this task?\n",
    "\n",
    "a) ```total_revenue = sum(item['quantity_sold'] * item['price_per_unit'] for item in sales_data if item['product_id'] == 'ABC123')```\n",
    "\n",
    "b) ```total_revenue = sum(item['quantity_sold'] * item['price_per_unit'] for item in sales_data if item['product_id'] != 'ABC123')```\n",
    "\n",
    "c) ```total_revenue = sum(item['quantity_sold'] * item['price_per_unit'] for item in sales_data if item['product_id'] != 'ABC123') / len(sales_data)```\n",
    "\n",
    "d) ```total_revenue = sum(item['quantity_sold'] * item['price_per_unit'] for item in sales_data) / len(sales_data)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555c54c-2dd4-49f4-bf50-2a0c0fe98bad",
   "metadata": {},
   "source": [
    "## Solution 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4e277-3396-41b8-bfc6-59980503481a",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60daba-c21b-4de0-8c18-68151fccf0eb",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c18f93-e015-404f-b8ba-b7601fc397f2",
   "metadata": {},
   "source": [
    "## Question 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c7424a-9f96-4b38-b8d8-9b2a6fed8fee",
   "metadata": {},
   "source": [
    "You are analyzing a dataset containing information about online orders, including the order ID, customer name, and total order amount. You need to calculate the total revenue generated from orders placed by customers with names starting with the letter ‘A’. Which of the following Python code snippets accomplishes this task?\n",
    "\n",
    "a) ```total_revenue = sum(order['total_amount'] for order in orders_data if order['customer_name'].startswith('A'))```\n",
    "\n",
    "b) ```total_revenue = sum(order['total_amount'] for order in orders_data if order['customer_name'].startswith('B'))```\n",
    "\n",
    "c) ```total_revenue = sum(order['total_amount'] for order in orders_data if order['customer_name'] == 'A')```\n",
    "\n",
    "d) ```total_revenue = sum(order['total_amount'] for order in orders_data if order['customer_name'] \n",
    "!= 'A')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108364bc-e256-4dd5-95d5-e73a288b4b8b",
   "metadata": {},
   "source": [
    "## Solution 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfc21f-c809-4c5b-9173-733bb415f396",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b875bb-c8c8-4eb0-91ec-f4680acd79f2",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082b967-3395-4379-ba5c-ca91d593e7aa",
   "metadata": {},
   "source": [
    "## Question 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b2e9d-ca94-4362-a4bc-a6f47688b15b",
   "metadata": {},
   "source": [
    "You have a list of strings ```[‘apple’, ‘banana’, ‘cherry’, ‘date’]``` in Python. You want to create a new list that includes only the strings starting with the letter ‘b’. Which of the following code snippets accomplishes this task?\n",
    "\n",
    "a) ```[item for item in original_list if item.startswith('b')]```\n",
    "\n",
    "b) ```[item if item.startswith('b') else None for item in original_list]```\n",
    "\n",
    "c) ```[item for item in original_list if item[0] == 'b']```\n",
    "\n",
    "d) ```[item if item[0] == 'b' else None for item in original_list]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cebdf-bbd6-4063-bde0-71309756af38",
   "metadata": {},
   "source": [
    "## Solution 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37b682-d580-4ea2-b726-4b063bcea229",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50666fca-01e9-4853-b40f-096fa399e530",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57840a0a-1c6a-4245-ab2f-eb9691373d53",
   "metadata": {},
   "source": [
    "## Question 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d8009-db91-4e47-8eb8-a3d076f10e53",
   "metadata": {},
   "source": [
    "You are working with a dataset containing customer information, including their age, income, and purchase history. You need to calculate the average age of customers who have made at least one purchase. Which of the following Python code snippets accomplishes this task?\n",
    "\n",
    "a) ```average_age = sum(customer['age'] for customer in customers if customer['purchase_history']) / len(customers)```\n",
    "\n",
    "b) ```average_age = sum(customer['age'] for customer in customers) / len(customers)```\n",
    "\n",
    "c) ```average_age = sum(customer['age'] for customer in customers if customer['purchase_history']) / len(customers if customers['purchase_history'])```\n",
    "\n",
    "d) ```average_age = sum(customer['age'] for customer in customers if customer['purchase_history']) / len(customers if customers['purchase_history'] else 1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04dd295-cc16-4fc1-a1e5-6d52edb0f456",
   "metadata": {},
   "source": [
    "## Solution 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc69b9c-c9b4-4317-bb7f-9a969f8a7cea",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61814a-ae08-453a-a2bd-ee561032f1cc",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0b18-a60b-491a-9b04-e8e6b8e9ea5d",
   "metadata": {},
   "source": [
    "## Question 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a229185-853c-4984-944d-d0e014c64b03",
   "metadata": {},
   "source": [
    "In cleaning a dataset for a health study, a data analyst notices several instances where the ‘age’ column contains values over 150 years. How should these data points be treated?\n",
    "\n",
    "a) As incomplete data, because the exact ages are not known.\n",
    "\n",
    "b) As valid data, considering potencial recording errors.\n",
    "\n",
    "c) As erroneous data, given the unrealistic age values.\n",
    "\n",
    "d) As duplicates data, if the same age appears multiple items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f07b3-e716-467c-8898-bfe7db5a0e5e",
   "metadata": {},
   "source": [
    "## Solution 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d8efe-fe71-40ee-a735-373a34c71f07",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5b379-eee7-4783-a2e2-aafecb0bf69a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ccb306-bc09-4f8f-b088-aa249e0e4ddb",
   "metadata": {},
   "source": [
    "## Question 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5ba6b-2f1c-40be-b6e0-b6a7868d2193",
   "metadata": {},
   "source": [
    "You need to validate data from a dataset containing numeric values. Which data validation technique should you use to ensure that numeric data falls within a specific range, such as 0 to 100?\n",
    "\n",
    "a) Completeness validation\n",
    "\n",
    "b) Range validation.\n",
    "\n",
    "c) Format validation.\n",
    "\n",
    "d) Data type validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd85f8c-6237-4b55-b7eb-6eba1557f312",
   "metadata": {},
   "source": [
    "## Solution 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ef645-c7b5-434a-b4b9-a7d6e98305b9",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a234b0a-03cc-4b36-be31-954950aae950",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ac8c5-1f4a-47b4-ba10-b36ffcc4451e",
   "metadata": {},
   "source": [
    "## Question 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5f0f8-8eac-4c1b-91b2-eafd192c32ee",
   "metadata": {},
   "source": [
    "A dataset used for analyzing traffic patterns has several entries where the ‘vehicle_speed’ column shows speeds exceeding the maximum possible speed for the road in question. How should these entries be classified?\n",
    "\n",
    "a) As complete data, because every entry has a speed value.\n",
    "\n",
    "b) As irrelevant data, assuming speed is not crucial for the analysis.\n",
    "\n",
    "c) As erroneous data, because the speeds exceed the maximum possible for the road.\n",
    "\n",
    "d) As outlier data, indicating potential data entry extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d6849-2990-40f9-9a70-b6dbc61ac1b1",
   "metadata": {},
   "source": [
    "## Solution 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd576de-2c94-489a-9427-7efa98c23b26",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183616e1-12af-4d8b-8fcb-1feabbb47ccc",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19561144-23f5-4050-95f5-1d560a094657",
   "metadata": {},
   "source": [
    "## Question 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325f7c2-112d-4884-a18a-e11540c6207c",
   "metadata": {},
   "source": [
    "You are working on a predictive model to classify emails as either Spam or Not Spam. You have built a model and it has an accuracy of 99% on your training dataset. However, when you test it on a new set of emails, the accuracy drops to 70%. What is most likely happening?\n",
    "\n",
    "a) Class Imbalance\n",
    "\n",
    "b) Overfitting\n",
    "\n",
    "c) Underfitting\n",
    "\n",
    "d) High Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ea725-4972-49ce-8dc4-a3c061254f0c",
   "metadata": {},
   "source": [
    "## Solution 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea594c-8abd-4e64-a04a-dcf7ac4d3c25",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed0f08-a1f1-4459-ad03-8ca6a72dbfc4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca8ace-bf3a-4c63-9ccd-9e91032151b3",
   "metadata": {},
   "source": [
    "## Question 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1945540-453d-41b6-8112-5dab2535ef87",
   "metadata": {},
   "source": [
    "Which of the following methods would be the most appropriate for importing a moderately-sized CSV file (around 500MB) into a Pandas DataFrame?\n",
    "\n",
    "a) `pd.read_csv('file.csv', chunksize=5000)`\n",
    "\n",
    "b) `pd.read_fwf('file.csv')`\n",
    "\n",
    "c) `pd.read_csv('file.csv')`\n",
    "\n",
    "d) `pd.read_csv('file.csv', dtype=category)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c2d1b-5b93-41da-8a38-f1eb81d78e57",
   "metadata": {},
   "source": [
    "## Solution 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b8d1a-adce-43db-995c-56e44c7abadd",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415cf07f-1ecd-48d8-bea1-0fd4d8c794de",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e588641-cde2-46df-9e6b-98097847d3ca",
   "metadata": {},
   "source": [
    "## Question 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9cf3d-83e6-469f-8257-9d40696c0d32",
   "metadata": {},
   "source": [
    "Which of the following methods is least likely to be effective when dealing with outliers in a dataset while using Python's Pandas library?\n",
    "\n",
    "a) Transformation\n",
    "\n",
    "b) Deleting the feature column.\n",
    "\n",
    "c) Capping\n",
    "\n",
    "d) Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a9077-4716-41a8-9f26-b0360df28aa3",
   "metadata": {},
   "source": [
    "## Solution 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ad76b-ad21-49a4-870d-c2528b5af8cd",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355a7cd-99f9-4bc8-b859-50ee4fc628db",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab5c06-3d0d-4eb9-b725-268fef05315a",
   "metadata": {},
   "source": [
    "## Question 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900da47-a48d-41a1-b425-d86061da5f91",
   "metadata": {},
   "source": [
    "You have a DataFrame employee_data as follows:\n",
    "\n",
    "\n",
    "`\n",
    "employee_data = pd.DataFrame({'Name': ['Alice', 'Bob', 'Carol'],\n",
    "'Skill': ['Python', 'Java', 'Python'],\n",
    "'Experience': [3, 4, 5]\n",
    "})\n",
    "`\n",
    "\n",
    "You want to reshape this DataFrame to show the sum of Experience for each Skill. Which code snippet will accomplish this?\n",
    "\n",
    "a)\n",
    "`\n",
    "employee_data.pivot_table(index='Skill', columns='Experience', values='Experience', aggfunc='sum')\n",
    "`\n",
    "\n",
    "b) \n",
    "`\n",
    "employee_data.set_index(['Name','Skill']).unstack().fillna(0)\n",
    "`\n",
    "\n",
    "c) \n",
    "`\n",
    "employee_data.pivot(index='Skill', columns='Experience', values='Experience').sum(axis=1)\n",
    "`\n",
    "\n",
    "d)\n",
    "`\n",
    "employee_data.groupby('Skill').Experience.sum()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60aa0b-5ee4-49c5-9ef4-1f96b8ad0451",
   "metadata": {},
   "source": [
    "## Solution 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1662761-66df-458a-bb5c-2baefbbfafa3",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e6d30-3a6f-43b1-bcfb-91a2a609057c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655f7c1-cac0-41b9-a3c5-c235868ea686",
   "metadata": {},
   "source": [
    "## Question 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba8e00-5e61-49d6-848d-4dc39d4616ff",
   "metadata": {},
   "source": [
    "You are given a DataFrame df with a column 'Date' of type string in the format 'YYYY-MM-DD'. You want to filter the rows where the year is 2024. Which of the following code snippets is the most efficient way to do so?\n",
    "\n",
    "a) `df[df['Date'].str.slice(0, 4) == '2024']`\n",
    "\n",
    "b) `df[df['Date'].apply(lambda x: x.split('-')[0]) == '2024']`\n",
    "\n",
    "c) `df[df['Date'].str.contains('2024')]`\n",
    "\n",
    "d) `df[pd.to_datetime(df['Date']).dt.year == 2024]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d63443-870e-4726-a614-9941b0e48d9f",
   "metadata": {},
   "source": [
    "## Solution 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c25dd-9c6e-4ac4-8080-df074a15cce0",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ef387-343a-4530-ac9e-5806cb6e4e84",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1374f3-59f5-42fc-b95f-edeaee7719fe",
   "metadata": {},
   "source": [
    "## Question 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21644c-8f4e-4369-bfbe-7bcdbffd14d9",
   "metadata": {},
   "source": [
    "Sarah has analyzed customer feedback data and created a bar chart showing customer satisfaction ratings for different products. How should Sarah effectively communicate the insight gained from this visualization to a non-technical audience?\n",
    "\n",
    "a) Present detailed statistical analysis results.\n",
    "\n",
    "b) Explain the methodology used to collect customer feedback.\n",
    "\n",
    "c) Use plain language to describe the overall satisfaction levels and compare ratings across products.\n",
    "\n",
    "d) Discuss the technical aspects of creating the bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8859fd-6d2a-4e33-8f61-dddedac6be24",
   "metadata": {},
   "source": [
    "## Solution 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9e46c-c61c-4064-803e-261cd37d6ded",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb79599-ee0d-4bd7-980c-fbbca86bbaa4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9649c-4547-4a3a-8d48-5a86a594b277",
   "metadata": {},
   "source": [
    "## Question 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199770b-a15f-491d-b44e-9ac437bc8258",
   "metadata": {},
   "source": [
    "Emma is presenting a scatter plot showing the correlation between marketing spend and sales revenue. How should Emma effectively communicate the insight gained from this visualization to a non-technical audience?\n",
    "\n",
    "a) Provide detailed explanations of data cleaning techniques.\n",
    "\n",
    "b) Use storytelling techniques to relate the scatter plot to real-word scenarios.\n",
    "\n",
    "c) Discuss the technical aspects of creating the scatter plot.\n",
    "\n",
    "d) Present statistical regression models used to analyze the correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066850a0-7678-40a4-ae13-f90a97a7db24",
   "metadata": {},
   "source": [
    "## Solution 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a957fbb-7cfc-4089-8d8b-5826ad49593b",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934924c3-e0f6-457b-84ea-84e4dd507f41",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b192b9-1bf0-4ac6-bc1c-577fcd7e44a4",
   "metadata": {},
   "source": [
    "## Question 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60aa73-935d-40be-a3a3-4607e8b2263c",
   "metadata": {},
   "source": [
    "You are preparing a quarterly financial report for a company, which includes revenue, expenses, profit margins, and year-over-year growth rates. What visualization technique is most appropriate for comparing revenue and expenses over the past four quarters?\n",
    "\n",
    "a) Line chart\n",
    "\n",
    "b) Bar chart\n",
    "\n",
    "c) Scatter plot\n",
    "\n",
    "d) Pie Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986904a4-1525-492b-99b7-9657d7883f13",
   "metadata": {},
   "source": [
    "## Solution 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6b8ac-87b9-47e4-a84c-6cfa2f506189",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2aa15-616b-4f32-8de5-374f0dddf492",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331644b3-e50f-4d62-a15e-94ff7d547080",
   "metadata": {},
   "source": [
    "## Question 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099810a-7ca4-4af2-9157-b8623f498cf3",
   "metadata": {},
   "source": [
    "Sarah has analyzed customer feedback data and created a bar chart showing customer satisfaction ratings for different products. How should Sarah effectively communicate the insight gained from this visualization to a non-technical audience?\n",
    "\n",
    "a) Present detailed statistical analysis result.\n",
    "\n",
    "b) Explain the methodology used to collect customer feedback.\n",
    "\n",
    "c) Use plain language to describe the overall satisfaction levels compare ratings across products.\n",
    "\n",
    "d) Discuss the technical aspects of creating the bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4c069-ba98-48ca-8996-c0c558a5524c",
   "metadata": {},
   "source": [
    "## Solution 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d149ed8-5c6c-48b1-a28b-c1cef98f8986",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85975d67-35f1-4290-8bee-99a4c63b54bb",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62eb335-e34f-489d-b62e-1373e132b0b7",
   "metadata": {},
   "source": [
    "## Question 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6acd660-0ff3-4df8-88e9-3b3cb2932b50",
   "metadata": {},
   "source": [
    "You are consolidating data from multiple CSV and Excel files into a single Pandas DataFrame. What is the most effective way to validate that the final DataFrame contains no missing or duplicate values?\n",
    "\n",
    "a) Use `DateFrame.describe()` to generate descriptive statistics for numerical columns.\n",
    "\n",
    "b) Use `pd.isnull()` to check for missing values and `pd.duplicated()` to check fro duplicates.\n",
    "\n",
    "c) Manually inspect the first and last rows of the DataFrame.\n",
    "\n",
    "d) Assume that Pandas automatically handles missing and duplicate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce392ffe-7e9e-4807-af55-3374a3561a04",
   "metadata": {},
   "source": [
    "## Solution 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8101e2-93cb-4f57-a858-236144e6b81a",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca0d17-c174-4579-99e0-c1a7be52efee",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a0fb4-4ab5-4c35-b2b0-8f87422a9fad",
   "metadata": {},
   "source": [
    "*Creado por:*\n",
    "\n",
    "*Isabel Maniega*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
